%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Created: 2011-08-14 17:43:38+02:00
% Main authors:
%     - Jérôme Pouiller <jezz@sysmic.org>
%

\part{Partage de ressources}

\begin{frame}
  \partpage
\end{frame}

\begin{frame}
  \tableofcontents[currentpart]
\end{frame}

\section{Ordonnancement avec contraintes de précédance}

\begin{frame}{Contraintes de précédence (1)} 
  Problèmatique: Une tâche $j$ doit s'éxecuter après $i$\\

  Les contraintes de précédence sur l'ordre d'exécution des tâches les
  unes par rapport aux autres sont généralement décrites par un graphe
  orienté:
  \begin{itemize}
  \item $i < j$ indique que  la tâche $i$ est un prédécesseur de
    $j$
  \item $i  → j$  indique que la  tâche $i$ est  un prédécesseur
    immédiat de $j$
  \end{itemize}
  \begin{center}
    \input{pics/constraint-graph}
  \end{center}
\end{frame}

\begin{frame}{Contraintes de précédence (2)} 
  \begin{itemize}
  \item Ici, seulement précédence simple: Les tâche dépendantes ont la même période
  \item Principe de l'établissement de l'ordonnancement :
    \begin{itemize} 
    \item Transformer l'ensemble des tâches dépendantes en un ensemble
      de  tâches \textbf{indépendantes} que  l'on ordonnancera  par un
      algorithme classique
    \item Par des modifications des  paramètres des tâches : si $i →
      j$ alors la règle de transformation doit respecter:
      \begin{itemize} 
      \item $r_j ≤ r_i$
      \item $P_i < P_j$
      \end{itemize} 
    \item  Validation  de   l'ordonnancabilité  selon  des  critères
      utilisés pour des tâches indépendantes
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Contraintes de précédence avec RM} 
  Contraintes  de  précédence  et  Rate Monotonic:  la  transformation
  s'opère hors ligne sur la date de réveil et sur les délais critiques
  \begin{itemize} 
  \item $r^*_i = \max\{r_i, r^*_j\}$ pour tous les $j$ tels que $j →
    i$
  \item si $i  → j$ alors $P_i > P_j$ dans  le respect de la
    règle d'affectation des priorités par Rate Monotonic
  \end{itemize}
\end{frame} 

\begin{frame}{Exemple - RM}
  \begin{center}
    \input{pics/constraint-graph}\\[2ex]

    \begin{tabular}{cccccc}
      \hline
      Tâche & Capacité & Arrivée  & $r^*_i$ & $P_i$\\
      \hline
      A & 1 & 0  &  \uncover<2->{0} & \uncover<3->{1}\\
      B & 2 & 5  &  \uncover<2->{5} & \uncover<3->{1}\\
      C & 2 & 0  &  \uncover<2->{0} & \uncover<3->{2}\\
      D & 1 & 0  &  \uncover<2->{5} & \uncover<3->{2}\\
      E & 3 & 0  &  \uncover<2->{5} & \uncover<3->{3}\\
      \hline
    \end{tabular}
  \end{center}
  \uncover<3->{A renouveller pour chaque période}
\end{frame}

\begin{frame}{Contraintes de précédence avec DM} 
  Contraintes de  précédence et Deadline  Monotonic: la transformation
  s'opère hors ligne sur la date de réveil et sur les délais critiques
  \begin{itemize}
  \item $r^*_i =  \max \left\{ r_i, r^*_j \right\}$  pour tous les $j$
    tels que $j → i$
  \item $D^*_i =  \max \left\{ D_i, D^*_j \right\}$  pour tous les $j$
    tels que $j → i$ (ne corrspond pas au délais critique réel)
  \item si  $i →  j$ alors  $P_i > P_j$  dans le  respect de  la règle
    d'affectation des priorités par Deadline Monotonic
  \end{itemize} 
\end{frame} 

\begin{frame}{Exemple - DM}
  \begin{center}
    \input{pics/constraint-graph}\\[2ex]

    \begin{tabular}{ccccccc}
      \hline
      Tâche & Capacité & Arrivée & Délai & $r^*_i$ & $D^*_i$ & $P_i$\\
      \hline
      A & 1 & 0 & 5  & \uncover<2->{0} & \uncover<3->{5}  & \uncover<4->{1}\\
      B & 2 & 5 & 7  & \uncover<2->{5} & \uncover<3->{7}  & \uncover<4->{3}\\
      C & 2 & 0 & 5  & \uncover<2->{0} & \uncover<3->{5}  & \uncover<4->{2}\\
      D & 1 & 0 & 10 & \uncover<2->{5} & \uncover<3->{10} & \uncover<4->{4}\\
      E & 3 & 0 & 12 & \uncover<2->{5} & \uncover<3->{12} & \uncover<4->{5}\\
      \hline
    \end{tabular}
  \end{center}
  \uncover<4->{A renouveller pour chaque période}
\end{frame}

\begin{frame}{Contraintes de précédence avec EDF} 
  Contraintes de précédence et EDF
  \begin{itemize}
  \item  modification des  échéances de  facon à  ce qu'une  tâche ait
    toujours un di inférieur à celui de ses successeurs (algorithme de
    Chetto et al.)
  \item une tâche ne doit être activable que si tous ses prédécesseurs
    ont terminé leur exécution
  \item modification de la date de réveil et de l'échéance
    \begin{itemize}
    \item $r^*_i = \max \left\{ r_i, \max \left\{ r^*_j + C_j \right\}
      \right\}$ pour tous les $j$ tels que $j → i$
    \item $d^*_i = \min \left\{ d_i, \min \left\{ d^*_j - C_j \right\}
      \right\}$ pour tous les $j$ tels que $i → j$
    \item on itère sur les prédécesseurs et successeurs immédiats
    \item  on commence les  calculs par  les tâches  qui n'ont  pas de
      prédécesseurs pour le calcul des $r$ et par les tâches qui n'ont
      pas de successeur pour le calcul des $d$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Exemple - EDF}
  \begin{center}
    \input{pics/constraint-graph}\\[2ex]

    \begin{tabular}{cccccc}
      \hline
      Tâche & Capacité & Arrivée & Délai & $r^*_i$ & $d^*_i$ \\
      \hline
      A & 1 & 0 & 5  & \uncover<2->{0} & \uncover<3->{3}  \\
      B & 2 & 5 & 7  & \uncover<2->{5} & \uncover<3->{7}  \\
      C & 2 & 0 & 5  & \uncover<2->{1} & \uncover<3->{5}  \\
      D & 1 & 0 & 10 & \uncover<2->{7} & \uncover<3->{9}  \\
      E & 3 & 0 & 12 & \uncover<2->{8} & \uncover<3->{12} \\
      \hline
    \end{tabular}
  \end{center}
  \uncover<3->{A renouveller pour chaque période}
\end{frame}

\section{Problèmatique des accès concurents}

\subsection{Protection des structures de données}

\begin{frame}[fragile]{Exemple de partage de données}
  Le partage de données entre les tâches posent les mêmes problème que
  le partage de données avec les interruptions

  Prennons deux tâches \c{f1} et \c{f2}:
  \begin{lstlisting}
int a = 0;
char t[255];
void f1() {
  t[a] = data1;
  a++;
}
void f2() {
  t[a] = data2;
  a++;
}
       \end{lstlisting}
\end{frame} 

\begin{frame}[fragile]{Exemple de partage de données}
Prennons le cas ou \verb+f1+ est préemptée par \verb+f2+:
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10]
t[a] = data1; // t[0];




a++;
// a = 2 maintenant
       \end{lstlisting}
     \end{column}
     \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10,escapeinside=\{\}]

t[a] = data2; 
// t[0] est {é}cras{é}!
a++;
// a = 1 maintenant


       \end{lstlisting}
    \end{column}
  \end{columns}

  Au lieu d'écrire  les deux donnée l'une après  l'autre, la valeur de
  \verb+data1+ est perdue alors  que \verb+t[1]+ contiendra une valeur
  aléatoire.
\end{frame} 

\subsection{Protection des ressources matériel}

\begin{frame}[fragile]{Exemple de ressource partagée}
  Cas d'un  périphérique réseau avec des registres  mappés en mémoire.
  Le  registre  \c{0xABC0}  permet  de  placer la  donnée  à  envoyer.
  L'écriture  d'un 1  sur  le registre  \c{0xABC4} permet  d'effectuer
  l'envoi:
\begin{lstlisting} 
void send(int data) {
  *0xABC0 = data;
  *0xABC4 = 1;
}
  \end{lstlisting} 
\end{frame} 

\begin{frame}[fragile]{Exemple de ressource partagée}
  Etudions le cas de l'éxecution simultanée de cette fonction par deux
  tâches.  La première tâche appelle \c{send} avec \cmd{data = 42}:
  \begin{lstlisting} 
*0xABC0 = 42
  \end{lstlisting} 
  La  tâche est  préemptée.  La  seconde tâche  appelle  \c{send} avec
  \cmd{data = 10}:
\begin{lstlisting} 
*0xABC0 = 10
*0xABC4 = 1
\end{lstlisting} 
  \c{10} est envoyé. La tâche 1 reprend la main:
\begin{lstlisting} 
*0xABC4 = 1
\end{lstlisting} 
  \c{10} (au lieu de \c{42}) est de nouveau envoyé.\\[3mm]

  Ce cas  est aussi valable dans  le cas d'une  interruption (bien que
  plus rare dans la pratique).
\end{frame} 

\subsection{Réentrance}

\begin{frame}{Comment éviter le problème?}
  Nous devons élargir ce que nous avons précédement vu pour le partage
  d'informations avec les interruptions.

  Les problèmes d'accès concurrents se traduisent très souvent par des
  \emph{races  conditions}.   C'est à  dire  des problèmes  aléatoires
  produit par une séquence particulière d'évènements
  \begin{itemize} 
  \item   Les  \emph{race  conditions}   sont  souvent   difficiles  à
    reproduire et à identifier
  \item Les  \emph{race conditions} peuvent être latente  dans le code
    et se déclarer suite à une modification de l'environnement externe
  \item Une race condition coûte chère (diffuculté de correction, peut
    potentiellement atterrir en production)
  \end{itemize} 
\end{frame}

\begin{frame}{Comment s'en protèger?}
  Comment s'en protèger?
  \begin{itemize} 
  \item  Ne  pas  utiliser  de  variables globales  ou  de  ressources
    partagées
  \item Utiliser des accès atomiques
  \item   Placer  des   accès   aux  ressources   partagée  dans   des
    \emph{sections critiques}
  \end{itemize} 
  Une  fonction  pouvant  être  appellée simultanénement  depuis  deux
  contextes de tâches différentes est dite \emph{réentrante}
\end{frame} 

\begin{frame}{Partage de ressources critiques} 
  Une ressource critique ne peut :
  \begin{itemize}
  \item être utilisée simultanément par plusieurs tâches
  \item être réquisitionnée par une autre tâche
  \end{itemize}
  Notion de section critique :
  \begin{itemize}
  \item  séquence  d'instructions pendant  lesquelles  on utilise  une
    ressource critique
  \item sans  problème dans le cas d'un  ordonnancement non préemptif,
    mais  c'est rarement  le cas  dans un  environnement temps  réel
  \item[⇒]  évaluation  du  temps  de réponse  très  difficile,  sinon
    impossible (abondante littérature !)
  \end{itemize}
\end{frame}

\subsection{Partage de ressource entre deux tâches: Fonctionnement d'un mutex}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Nécessite une instruction assembleur  premettant un accès en lecture
  et une écriture  en une instruction: \\
  \texttt{test\_and\_set} affecte le registre d'état en fonction de la
  valeur  du registre  et affecte  la valeur  1 au  registre.  On peut
  développer la fonction \c{lock} à partir de là:
  \begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m))
    schedule();
}

void unlock(mutex_t *m) {
  m = 0;
  schedule();
}
  \end{lstlisting} 
\end{frame}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Un peu mieux:
  \begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m)) {
    this_task.reason = m;
    this_task.state = stop;
    schedule();
  }
}

void unlock(mutex_t *m) {
  m = 0;
  foreach (i in tasks)
    if (i.state == stop && i.reason == m)
      i.state = run;
  schedule();
}
  \end{lstlisting}
\end{frame} 

\section{Problème liés aux partage de ressources}

\begin{frame}{Problèmes associés aux sections critiques}
  Voici les problèmes à prendre en considération lors de l'utilisation
  de sections critiques:
  \begin{itemize}
  \item Dead Lock
  \item Latence induite
  \item Inversion de priorité
  \end{itemize} 
\end{frame}

\subsection{Dead Lock}

\begin{frame}[fragile]{Dead lock}
  \begin{itemize} 
  \item Aussi appellé \emph{étreinte fatale}
  \item Deux tâches utilisent  deux ressources imbriquées dans l'ordre
    inverses
  \end{itemize} 
  \begin{columns}
    \begin{column}{5cm}
      Tache 1:
      \begin{lstlisting}[showlines=true,emptylines=10]
lock(m1);



lock(m2);
      \end{lstlisting} 
    \end{column}
    \begin{column}{5cm}
      Tache 2:
      \begin{lstlisting}[showlines=true,emptylines=10]

lock(m2);
// Deadlock ici:
lock(m1);

      \end{lstlisting} 
    \end{column}
  \end{columns}
  \begin{center}
    \input{pics/cs-deadlock.tex}
  \end{center}
\end{frame} 

\begin{frame}[fragile]{Dead lock}
  \textbf{Remarque:} \\
  Le code suivant:
  \begin{lstlisting} 
lock(m);
lock(m); 
  \end{lstlisting} 
  entraine un  \emph{double lock},  un type particulier  de \emph{Dead
    lock}
\end{frame} 

\begin{frame}[fragile]{Mutex dans une interruption}
  \textbf{Remarque:} \\
  Ne jamais utiliser de mutex dans une interruption.
  \begin{itemize} 
  \item Si  la ressource  est occuppée par  la tâche qui  vient d'être
    préemptée, le \texttt{lock()} s'éxécutera dans le même contexte
  \item[$\rightarrow$] Double lock
  \item De plus,  le blocage d'un mutex peut  entrainer peut entrainer
    une  très  important latence  ce  qui  est  en contradiction  avec
    l'objectif de rester le minimum de temps dans une interruption
  \item[$\rightarrow$] Règle générale: Il ne faut pas appeller \texttt{schedule} dans une interruption.
  \end{itemize} 
\end{frame} 

\subsection{Latence introduite}

\begin{frame}{Latence}
  \begin{itemize} 
  \item  Cas d'une tâche  de faible  priorité utilisant  une ressource
    d'une tâche de haute priorité.
  \item Existe uniquement en environnement préemptif
  \end{itemize} 
  Exemple avec deux tâches $P_A > P_C$:
  \begin{itemize} 
  \item Cas sans partage de ressource:
    \begin{columns}
      \begin{column}{6cm}
        % AABBBAAAA
        \begin{center}
          \input{pics/cs-latency-1}
        \end{center}
      \end{column}
      \begin{column}{4cm}
        $$TR_A = 3$$
      \end{column}
    \end{columns}
  \item Cas avec une ressource partagée:
    \begin{columns}
      \begin{column}{6cm}
        % AABAAABBA
        \begin{center}
          \input{pics/cs-latency-2}
        \end{center}
      \end{column}
      \begin{column}{4cm}
        $$TR_A = 6$$
      \end{column}
    \end{columns}
  \end{itemize}     
\end{frame} 

\subsection{Inversion de priorité}

\begin{frame}{Inversion de priorité}
  \begin{itemize} 
  \item Phénomène dû à la présence simultanée de priorités fixes et de
    ressources à accès exclusif dans un environnement préemptif
  \item  Une  tâche  de  priorité  intermédiaire peut  être  élue  par
    l'ordonnanceur  alors  que  des  tâches  de  plus  haute  priorité
    attentent.
  \item Il est diffile de calculer  le temps de blocage des tâches par
    une inversion de priorité (il est généralement non-borné)
  \end{itemize} 
  Cas notable de \emph{Path Finder}
\end{frame}

\begin{frame}{Inversion de priorité}
  \textbf{Exemple:}\\
  On ajoute à l'exemple précédent une  tâche $B$ telle que : 
  $P_A > P_B > P_C$
  \begin{itemize} 
  \item   Cas sans partage de ressource:
    % AABBBBCCCCCCCCCAA
    \begin{center}
      \input{pics/cs-pi-1}
    \end{center}
  \item   Cas avec un mutex:
    % AABCCCCCCCCCABBBA
    \begin{center}
      \input{pics/cs-pi-2}
    \end{center}
    La tâche $B$  s'éxecute alors qu'elle a une  priorité inférieure à
    $A$ et ne partage aucune ressource avec $A$.
  \end{itemize} 
\end{frame} 

\begin{frame}{Temps de réponse}
  Avec  les  ressources  partagées:
  \begin{itemize} 
  \item  Le  temps de  réponse  avec  un  algorithme à  priorité  fixe
    devient:
    $$TR_i = B_i + C_i + \sum_{P_j > P_i} \left\lceil\frac{TR_i}{T_j}\right\rceil C_j$$
  \item  $B_i$  est le  temps  de  blocage de  la  tâche  $i$ par  une
    ressource
    détenue par une tâche de priorité inférieure.
  \item $B_i$ est difficile à calculer
  \item La  condition nécessaire d'ordonnancabilité  par un algorithme
    Rate Monotonic devient:
    $$\forall i \in tasks, \left( \sum_{k \in tasks} \frac{C_k}{T_k} \right) + \frac{B_i}{T_i} ≤ i \left(2^{\frac{1}{i}}-1\right)$$
    \note{Formule à vérifier}
  \end{itemize} 
\end{frame}

\begin{frame}{Conseils}
  \begin{itemize} 
  \item Essayer de limiter la taille des sections critique
  \item  Essayer  de découper  les  sections  critiques  de manière  à
    favoriser la préemption des tâches de haute priorité
  \item Essayer de  diminuer la granularité des mutex  afin de limiter
    la taille des sections critiques.
  \end{itemize} 
\end{frame} 

\section{Solutions}

\subsection{Priority inheritence}

\begin{frame}{Héritage de priorité}
  \begin{itemize} 
  \item Aussi appellé \emph{Priority inheritence}
  \item Principe: Si  une tâche bloque une ressource  demandée par une
    tâche  de plus  haute  priorité, elle  acquiert temporairement  la
    priorité de la tâche de haute priorité.
  \item Attention à la gestion de l'héritage en cascade.
  \item  L'algorithme parait  simple,  mais c'est  assez complexe.  Il
    existe même des cas problèmatiques (dont le cout de résolution est
    polynomial)   dans   le   cas   d'architectures   multiprocesseurs
    symétriques sur des \cmd{rw\_lock}.
  \end{itemize} 
  Exemple précédent:
  % AABABBBCCCCCCCCCA
  \begin{center}
    \input{pics/cs-pi-3}
  \end{center}
\end{frame} 

\begin{frame}{Héritage de priorité}
  Autre exemple:
  Soit 3 tâches et 2 ressources telle que A et B partage la première ressource et B et C partage la seconde:
  $$P_A > P_B > P_C$$
  % CCBBCACBABC  
  \begin{center}
    \input{pics/pi-1}
  \end{center}
\end{frame} 

\begin{frame}{Héritage de priorité} 
  Concernant le temps de réponse  des tâches dans un système intégrant
  l'héritage de priorité:
  \begin{itemize}
  \item Le  temps de blocage $B_i$  d'une tâche de  haute priorité par
    une tâche de plus basse priorité nominale est borné
  \item ...  mais le calcul de  ce temps de blocage maximum reste très
    complexe
  \end{itemize}
\end{frame}

\begin{frame}{Problème rémanent} 
  \begin{itemize}
  \item Blocages en  chaîne (cf. notre exemple avec  3 tâches) rendent
    le calcul des temps de réponses complexes
  \item Deadlock
  \end{itemize}
\end{frame}

\subsection{Original ceiling priority}

\begin{frame}{Priorité plafonnée originale}
  \begin{itemize} 
  \item  Aussi  appellée   \emph{Original  Ceiling  Priority  Protocol
      (OCPP)} ou tout simplement \emph{Ceiling Priority}
  \item Introduit  à la  fin des années  80 pour résoudre  le problème
    d'inversion de priorité tout en prévenant l'occurence de deadlocks
    et de blocages en chaîne
  \item Amélioration  du protocole d'héritage de priorité  : une tâche
    ne peut pas entrer dans une section critique s'il y a un sémaphore
    acquis qui pourrait la bloquer
  \item Principe : on attribue à chaque sémaphore une priorité plafond
    égale  à  la  plus   haute  priorité  des  tâches  qui  pourraient
    l'acquérir. Une  tâche ne pourra  entrer dans la  section critique
    que si  elle possède une  priorité supérieure à toutes  celles des
    priorités plafond des sémaphores acquis par les autres tâches
  \end{itemize} 
\end{frame} 

\begin{frame}{Algorithme}
  \begin{itemize} 
  \item  On attribue  à chaque  sémaphore $S_k$  une  priorité plafond
    $C(S_k)$ égale à la plus haute priorité des tâches susceptibles de
    l'acquérir
  \item Soit  $i$ la tâche prête  de plus haute priorité  : l'accès au
    processeur est donné à $i$
  \item Soit $S_*$ le sémaphore  dont la priorité plafond $C(S_*)$ est
    la  plus grande  parmi tous  les  sémaphores déjà  acquis par  des
    tâches autres que $i$
  \item Pour entrer dans une  section critique gardée par un sémaphore
    $S_k$,  $i$  doit  avoir  une priorité  strictement  supérieure  à
    $C(S_*)$. Si  $P_i ≤ C(S_*)$, l'accès  à $S_k$ est  interdit et on
    dit  que  $i$ est  bloquée  sur $S_*$  par  la  tâche qui  possède
    $S_*$. La priorité de $i$  est alors passée à la tâche proriétaire
    de $S_*$
  \end{itemize} 
\end{frame} 

\subsection{Immediate Priority ceilling}

\begin{frame}{Priorité plafonnée immédiate}
  \begin{itemize} 
  \item  Aussi  appellée  \emph{Immediate  Ceiling  Priority  Protocol
      (ICPP)} ou \emph{Hightest Lock}
  \item Similaire à OCPP mais plus simple.
  \item Dès  qu'une tâche acquiert une sémaphore  $S_k$, elle acquiert
    sa priorité $C(S_k)$ en même temps
  \end{itemize} 
\end{frame} 

\begin{frame}{Exemple}
  \begin{center}
    \begin{tabular}{ccccc}
      \hline
      Tâche & Arrivée & Priorité & Capacité & Ressources \\
      \hline
      A & 4 & 1 & 5 & \texttt{\_\_12\_}\\
      B & 2 & 2 & 4 & \texttt{\_22\_}\\
      C & 2 & 3 & 2 & \texttt{\_\_}\\
      D & 0 & 4 & 6 & \texttt{\_1111\_}\\
      \hline
    \end{tabular}
  \end{center}
  \begin{overprint}
    \onslide<1>

    \onslide<2>
    Sans mécanisme de protection
    \begin{center}
      \input{pics/prio-inherit-1.tex}
      \begin{tabular}{cccc}
        $TR_A = 12$ & $TR_B = 6$ & $TR_C = 8$ & $TR_D = 17$\\
      \end{tabular}
    \end{center}
    
    \onslide<3>
    Par héritage de priorité
    \begin{center}
      \input{pics/prio-inherit-2.tex}
      \begin{tabular}{cccc}
        $TR_A = 9$ & $TR_B = 12$ & $TR_C = 14$ & $TR_D = 17$\\
      \end{tabular}
    \end{center}

    \onslide<4>
    Par \emph{Priority Ceiling}, les priorités plafond sont donc: 
    \begin{itemize}
    \item $C(S_1) = P_A$ 
    \item $C(S_2) = P_A$ 
    \end{itemize}

    \onslide<5>
    Par priorité plafonnée originale:
    \begin{center}
      \input{pics/prio-inherit-3.tex}
      \begin{tabular}{cccc}
        $TR_A = 7$ & $TR_B = 12$ & $TR_C = 14$ & $TR_D = 17$\\
      \end{tabular}
    \end{center}

    \onslide<6>
    Par priorité plafonnée immédiate:
    \begin{center}
      \input{pics/prio-inherit-4.tex}
      \begin{tabular}{cccc}
        $TR_A = 6$ & $TR_B = 12$ & $TR_C = 14$ & $TR_D = 17$\\
      \end{tabular}
    \end{center}
  \end{overprint}
\end{frame} 

% \begin{frame}{Priorité plafonnée} 
%   \begin{itemize}
%   \item à t = 0, T2 est activée et démarre.
%   \item à t =  1, Le sémaphore S2 est demandé et  obtenu (il n'y a pas
%     d'autre ressource en cours d'utilisation)
%   \item à t = 2, T1 est activée et préempte T2
%   \item à t = 3, T1 demande  S2 et est bloquée par le protocole car la
%     priorité de T1 n'est pas supérieure à la priorité plafond $C(S2)=P1$
%     (S2 est le seul sémaphore acquis à t2) T2 hérite de la priorité de
%     T1 et redémarre
%   \item à t  = 4, T2 demande  et obtient le sémaphore S1  , car aucune
%     autre tâche ne détient de ressource
%   \item à t = 5 T0 est réveillée et préempte T2
%   \item  à t =  6, T0  demande le  sémaphore S0  qui n'est  détenu par
%     aucune autre tâche. Le protocole  bloque néanmoins T0 parce que sa
%     priorité n'est  pas supérieure à  la plus grande  priorité plafond
%     des sémaphores  déjà détenus  (S2 et  S1) : P0.   T2 hérite  de la
%     priorité de T0 et peut redémarrer
%   \item à t = 7 , T2 relâche S1. Sa priorité p2 est ramenée à P1, plus
%     haute priorité des tâches bloquées par T2. T0 peut alors préempter
%     T2 et acquérir S0
%   \item à t = 9 quand T0 demande S1, le seul sémaphore encore tenu est
%     S2 avec  une priorité plafond  $P1 \leftarrow T0$ (priorité  $P0 >
%     P1$) obtient S1
%   \item à  t =  10, T0  se termine. T2  peut reprendre  son exécution,
%     toujours avec la même priorité P1
%   \item à t =  11, T2 relâche S2. Sa priorité est  ramenée à sa valeur
%     nominale P2. T1 peut alors préempter T2 et redémarrer
%   \item à t = 12, T1 se termine, T2 peut redémarrer et se terminer
%   \end{itemize}
% \end{frame}

% \begin{frame}{Autre Exemple}
%   Par héritage de priorité
%   % CCBBACCAABAABC
%   \begin{center}
%     \begin{tikzpicture}[scale=0.5]
%       \timeline{14}{-5}{-1./A, -2.5/B, -4./C, }
%       \fill[cgreen]  (0,-1.5) \lo 2 \lo 2 \hi 1 \lo 2 \hi 2 \lo 1 \hi 2 \lo 1 \lo 1;
%       \fill[cred]    (0,-3.0) \lo 2 \hi 2 \lo 1 \lo 2 \lo 2 \hi 1 \lo 2 \hi 1 \lo 1;
%       \fill[cblue]   (0,-4.5) \hi 2 \lo 2 \lo 1 \hi 2 \lo 2 \lo 1 \lo 2 \lo 1 \hi 1;
%       \pb{0}{-1}{cgreen};
%       \pb{2}{-2.5}{cred};
%       \pb{4}{-4}{cblue};
%       \pattern[pattern=north east lines] (1, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (7, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (4, -4.5) rectangle +(2, 1);
%       \pattern[pattern=north west lines] (3, -3.0) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (9, -3.0) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (10, -1.5) rectangle +(1, 1);
%     \end{tikzpicture}
%   \end{center}
% \end{frame} 

% \begin{frame}{Autre Exemple}
%   Par priorité plafonnée:
%   % CCBCACAAAABBBC
%   \begin{center}
%     \begin{tikzpicture}[scale=0.5]
%       \timeline{14}{-5}{-1./A, -2.5/B, -4./C, }
%       \fill[cgreen]  (0,-1.5) \lo 2 \lo 1 \lo 1 \hi 1 \lo 1 \hi 4 \lo 3 \lo 1;
%       \fill[cred]    (0,-3.0) \lo 2 \hi 1 \lo 1 \lo 1 \lo 1 \lo 4 \hi 3 \lo 1;
%       \fill[cblue]   (0,-4.5) \hi 2 \lo 1 \hi 1 \lo 1 \hi 1 \lo 4 \lo 3 \hi 1;
%       \pb{0}{-1}{cgreen};
%       \pb{2}{-2.5}{cred};
%       \pb{4}{-4}{cblue};
%       \pattern[pattern=north east lines] (1, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (3, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (5, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (6, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (8, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (10, -3.0) rectangle +(2, 1);
%     \end{tikzpicture}
%   \end{center}
% \end{frame} 

\begin{frame}{Priorité plafonnée} 
  On a  le même critère d'ordonnancabilité  par RM que dans  le cas du
  protocole d'héritage de priorité:
  $$\forall i \in tasks, \left( \sum_{k \in tasks} \frac{C_k}{T_k} \right) + \frac{B_i}{T_i} ≤ i \left(2^{\frac{1}{i}}-1\right)$$
  et le même calcul du temps de réponse:
  $$TR_i = B_i + C_i + \sum_{P_j > P_i} \left\lceil\frac{TR_i}{T_j}\right\rceil C_j$$
  mais le calcul du temps de  blocage maximum de chaque tâche est plus
  simple :
  \begin{itemize}
  \item on peut démontrer que le temps de bloquage maximum $B_i$ d'une
    tâche $i$  est la durée de  la plus longue  des sections critiques
    ($\max  SC_{j,k}$)  parmi  celles  appartenant  à  des  tâches  de
    priorité inférieure à $P_i$ et  gardées par des sémaphores dont la
    priorité plafond est supérieure ou égale à $P_i$
    $$B_i = \max SC_{j,k} | P_j < P_i, C(S_k) ≥ P_i$$ 
  \end{itemize}
\end{frame}

\note{Reprendre l'exemple d'OCCP et appliquer cette formule dessus}

\section{Autres mécanismes de gestion d'accès concurrents}

\note{Pour chacun  des mécanisme,  donner les fonction  dasn plusieurs
  API,  faire  un exemple  ou  mieux,  donner  le code:  Posix,  Java,
  Xenomai, ucosII, vxWorks}

\subsection{Désactivation de l'ordonnanceur}

\begin{frame}{Désactivation de l'ordonnanceur}
  \begin{itemize} 
  \item On demande à l'OS de ne plus être préemptif
  \item Horriblement dangereux
  \item A  priori, à  ne jamais  utiliser sauf pour  faire des  cas de
    tests
  \end{itemize} 
\end{frame} 

\subsection{Sémaphore}

\begin{frame}{Sémaphore}
  \begin{itemize} 
  \item  Différence entre un  mutex et  un semaphore  binaire: presque
    aucune.
  \item Parfois le sémaphore  binaire est utilisé pour implémentéer le
    mutex.
  \item Toutefois,  d'un point de  vue sémantique, on pourrait  que le
    mutex  permet  d'avoir un  morceau  de  code mutuelement  exclusif
    tandis  que le  sémaphore est  une section  de code  limité  à une
    ressource.
  \item  Généralement,  les algorithmes  d'héritage  de priorité  sont
    implémentés sur les mutex mais pas sur les sémaphore.
%  \item  Notons  aussi  que  les  algorithmes  d'héritage  de  priorité
%    sont encore plus complexe sur les sémaphores
  \end{itemize} 
\end{frame} 

\subsection{Mutex réentrant}

\begin{frame}{Mutex Réentrant}
  \begin{itemize} 
  \item Idem  mutex, mais  si la même  tâche tente de  revérouiller le
    même mutex, le mutex est non-bloquant.
  \item Dans le cas  d'un mutex non-réentrant, ceci entraine forcement
    un dead-lock.
  \item Un sémaphore est maintenu pour connaitre le nombre de passage.
  \end{itemize} 
\end{frame} 

\subsection{R/W Lock}

\begin{frame}[fragile]{Read/Write Lock}
\note{\url{http://en.wikipedia.org/wiki/Readers-writers\_problem}}

Permet de limiter le phénomène  de latence en dimiminuant le nombre de
sections critiques.

Solution 1 (\emph{reader preference}):
\begin{columns}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_lock() {
  // mutex protege read_count
  lock(mutex);
  readcount++;
  if (readcount == 1)
    lock(w);
  unlock(mutex);
}
    \end{lstlisting} 
  \end{column}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount = 0)
    unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(w);
}
void write_unlock() {
  unlock(w);
}
    \end{lstlisting} 
  \end{column}
\end{columns}
\end{frame} 

\begin{frame}[fragile]{Read/Write Lock}
  Problème: un accès en écriture doit attendre que toutes les lectures
  soient terminées. Solution 2 (\emph{writer preference}):
  \begin{columns}
    \begin{column} {5cm}
      \begin{lstlisting} 
void read_lock() {
  lock(r);
  lock(mutex);
  readcount++;
  if (readcount == 1)
     lock(w);
  unlock(mutex);
  unlock(r);
  // r n'est pas bloque durant la lecture
}
       \end{lstlisting} 
     \end{column}
     \begin{column} {5cm}
       \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount == 0)
     unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(r);
   lock(w);
}
void write_unlock() {
  unlock(w);
  unlock(r);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\subsection{Rendez-vous ou barrier}
\begin{frame}[fragile]{Rendez-vous}
  Permet de synchroniser  deux tâches. La première tâche  arrivée à la
  barrière attend la seconde.
\begin{lstlisting} 
void init() {
  lock(m1);
  lock(m2);
}
\end{lstlisting}
Tâche 1:
\begin{lstlisting} 
  unlock(m1);
  lock(m2);
\end{lstlisting} 
Tâche 2:
\begin{lstlisting} 
  unlock(m2);
  lock(m1);
\end{lstlisting} 
\end{frame}

\subsection{Condition}

\begin{frame}[fragile]{Conditions}
  Peuvent  être   considérés  comme  des   \emph{rendez-vous}  à  sens
  unique. Si une tâche attend, elle est débloquée, sinon, aucun effet.
  Très utilisée pour le pattern des \cmd{work-thread}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting} 
void init() {
  lock(m);
}

void wait() {
  lock(m);
}

void signal() {
  unlock(m);
  try_lock(m);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5.5cm}
      \begin{lstlisting} 
// broadcast debloque
// tous les waiters alors
// que signal en debloque
// uniquement un
void broadcast()  {
  // Plus complexe, il
  // faut un mutex par
  // waiters. 
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\subsection{Buffer circulaire et Queue}

\begin{frame}[fragile]{Buffer circulaire et Queue}
  \begin{itemize} 
  \item  Précédement décrit dans  la section  ``Partage d'information
    avec les interruptions''
  \item Fonctionne aussi très bien entre les tâches
  \item Une  des rare structure  permettant d'être partagée à  la fois
    avec une interruption et des tâches
  \item Faire attention à l'allocation dynamique des objets
  \end{itemize}
\end{frame} 

\subsection{Spin Lock, Mutex et désactivation des interruptions}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  Lorsque:
  \begin{itemize} 
  \item  Vos  sections critique  font  intervenir  des  tâches et  des
    interruptions
  \item Votre problème ne concerne  pas un échange de données (et donc
    le buffer circulaire n'est pas une solution)
  \item Vous ne pouvez pas faire autrement
  \end{itemize} 
  alors,   vous  devez   combiner  les   trois   mécanismes  suivants:
  Désactivation des interruptions, Mutex et Spin Lock.

  Le point sur ces trois mécanismes:
  \begin{itemize} 
  \item  Si  une  ressource  est   partagé  entre  une  tâche  et  une
    interruption sur  le même coeur,  il est nécessaire  de désactiver
    les interruptions
  \item  Si une ressource  est partagé  entre deux  tâche sur  un même
    coeur, il est nécessaire d'utiliser un mutex
  \item Si  la ressource est  partagée avec un  autre coeur et  que le
    temps d'utilisation est court, utilisez un Spin Lock.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  On pourrait imaginer un cas cummulant les trois contraintes:
  \begin{lstlisting} 
disable_interrupts()
mutex_lock(m)
spin_lock(s)
a++
spin_unlock(s)
mutex_unlock(m)
enable_interrupts()
  \end{lstlisting} 
  Globalement, évitez!
\end{frame} 

\subsection{Algorithmes non-bloquants}

\begin{frame}{Algorithmes non-bloquants}
  \begin{itemize} 
  \item Algorithme thread-safe n'utilisant pas de sections ciritques. 
  \item Ces  algorithmes utilisent souvant  des instructions atomiques
    proposés par certains processeurs
  \item Par conséquant, ils sont peu portables
  \item Souvent utilisé dans les base de données
  \end{itemize} 
\end{frame} 

\subsection{Read-Copy-Update (RCU)}

\begin{frame}{Read-Copy-Update (RCU)}
  Type d'algorithme non bloquant:
  \begin{itemize} 
  \item La lecture n'est pas bloquante
  \item On note le nombre de lecteurs
  \item Les modification s'effectuent sur une copie de l'objet
  \item Les lecture suivante se font sur la nouvelle version de l'objet
  \item Lorsque  le dernier lecteur  a terminé, l'objet  d'origine est
    détruit. Seul subsiste la nouvelle version.
  \end{itemize} 
\end{frame}

\begin{frame}[fragile]{Exemple : Manipulation de listes} 
  \begin{center}
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
typedef struct {
   struct a_t a;
   int count_usage = 0;
   bool obsolete = false;
} rcu_t;
rcu_t *a = malloc(sizeof(rcu_t)); 
    \end{lstlisting}
  \end{center}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void read_a() {
  // lock:
  rcu_t *ptr = a;
  ptr->count_usage++;
  // do something with ptr;
  // unlock:
  ptr->count_usage--;
  if (ptr->obsolete && !ptr->count_usage)
    free(ptr);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5cm}
      \begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{colBasic},commentstyle=\scriptsize\itshape\color{colComments},numbers=none]
void write_a() { 
   struct rcu_t *a3 = a;
   struct rcu_t *a2 = malloc(sizeof(rcu_t));
   memcpy(a2, a);
   // modify a2;   
   a = a2;  
   a3->obsolete = true;
   if (!a3->count_usage)
      free(ptr);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

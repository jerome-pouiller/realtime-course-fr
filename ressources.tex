%
% This document is available under the Creative Commons Attribution-ShareAlike
% License; additional terms may apply. See
%   * http://creativecommons.org/licenses/by-sa/3.0/
%   * http://creativecommons.org/licenses/by-sa/3.0/legalcode
%
% Created: 2011-08-14 17:43:38+02:00
% Main authors:
%     - Jérôme Pouiller <jezz@sysmic.org>
%

\part{Partage de ressources}

\section{Ordonnancement avec contraintes de précédance}

\begin{frame}{Contraintes de précédence (1)} 
  \begin{itemize}
  \item ici,  seulement précédence simple: si $i$  est périodique de
    période $T_i$, alors $j$ l'est aussi et $T_j$
  \item principe de l'établissement de l'ordonnancement :
    \begin{itemize} 
    \item transformer l'ensemble des tâches dépendantes en un ensemble
      de  tâches \textbf{indépendantes} que  l'on ordonnancera  par un
      algorithme classique
    \item par des modifications des  paramètres des tâches : si $i →
      j$ alors la règle de transformation doit respecter:
      \begin{itemize} 
      \item $r_j ≤ r_i$
      \item $P_i < P_j$
      \end{itemize} 
    \item  validation  de   l'ordonnancabilité  selon  des  critères
      utilisés pour des tâches indépendantes
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Contraintes de précédence (2)} 
  Contraintes  de  précédence  et  Rate Monotonic:  la  transformation
  s'opère hors ligne sur la date de réveil et sur les délais critiques
  \begin{itemize} 
  \item $r^*_i = \max\{r_i, r^*_j\}$ pour tous les $j$ tels que $j →
    i$
  \item si $i  → j$ alors $P_i > P_j$ dans  le respect de la
    règle d'affectation des priorités par Rate Monotonic
  \end{itemize}
\end{frame} 

\begin{frame}{Contraintes de précédence (2)} 
  Contraintes de  précédence et Deadline  Monotonic: la transformation
  s'opère hors ligne sur la date de réveil et sur les délais critiques
  \begin{itemize}
  \item $r^*_i =  \max \left\{ r_i, r^*_j \right\}$  pour tous les $j$
    tels que $j → i$
  \item $D^*_i =  \max \left\{ D_i, D^*_j \right\}$  pour tous les $j$
    tels que $j → i$
  \item  si $i  →  j$  alors $P_i  >  P_j$ dans  le
    respect de la règle d'affectation des priorités par DMA
  \end{itemize} 
\end{frame} 

\begin{frame}{Contraintes de précédence (2)} 
  Les contraintes de précédence sur l'ordre d'exécution des tâches les
  unes par rapport aux autres sont généralement décrites par un graphe
  orienté:
  \begin{itemize}
  \item $J_a < J_b$ indique que  la tâche $J_a$ est un prédécesseur de
    $J_b$
  \item $J_a  → J_b$  indique que la  tâche $J_a$ est  un prédécesseur
    immédiat de $J_b$
  \end{itemize}
 \end{frame}

\begin{frame}{Contraintes de précédence (3)} 
  Contraintes de précédence et EDF
  \begin{itemize}
  \item  modification des  échéances de  façon à  ce qu'une  tâche ait
    toujours un di inférieur à celui de ses successeurs (algorithme de
    Chetto et al.)
  \item une tâche ne doit être activable que si tous ses prédécesseurs
    ont terminé leur exécution
  \item modification de la date de réveil et de l'échéance
    \begin{itemize}
    \item $r^*_i = \max \left\{ r_i, \max \left\{ r^*_j + C_j \right\}
      \right\}$ pour tous les $j$ tels que $j → i$
    \item $d^*_i = \min \left\{ d_i, \min \left\{ d^*_j - C_j \right\}
      \right\}$ pour tous les $j$ tels que $i → j$
    \item on itère sur les prédécesseurs et successeurs immédiats
    \item  on commence les  calculs par  les tâches  qui n'ont  pas de
      prédécesseurs pour le calcul des $r$ et par les tâches qui n'ont
      pas de successeur pour le calcul des $d$
    \end{itemize}
  \end{itemize}
  \note{Ajouter des exemples, etc...}
\end{frame}

\section{Problèmatique des accès concurents}

\subsection{Protection des structures de données}

\begin{frame}[fragile]{Exemple de partage de données}
  Le partage de données entre les tâches posent les mêmes problème que
  le partage de données avec les interruptions

  Prennons deux tâches \c{f1} et \c{f2}:
  \begin{lstlisting}
int a = 0;
char t[255];
void f1() {
  t[a] = data1;
  a++;
}
void f2() {
  t[a] = data2;
  a++;
}
       \end{lstlisting}
\end{frame} 

\begin{frame}[fragile]{Exemple de partage de données}
Prennons le cas ou \verb+f1+ est préemptée par \verb+f2+:
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10]
t[a] = data1; // t[0];




a++;
// a = 2 maintenant
       \end{lstlisting}
     \end{column}
     \begin{column}{5cm}
      \begin{lstlisting}[showlines=true,emptylines=10,escapeinside=\{\}]

t[a] = data2; 
// t[0] est {é}cras{é}!
a++;
// a = 1 maintenant


       \end{lstlisting}
    \end{column}
  \end{columns}

  Au lieu d'écrire  les deux donnée l'une après  l'autre, la valeur de
  \verb+data1+ est perdue alors  que \verb+t[1]+ contiendra une valeur
  aléatoire.
\end{frame} 

\subsection{Protection des ressources matériel}

\begin{frame}[fragile]{Exemple de ressource partagée}
  Cas d'un  périphérique réseau avec des registres  mappés en mémoire.
  Le  registre  \c{0xABC0}  permet  de  placer la  donnée  à  envoyer.
  L'écriture  d'un 1  sur  le registre  \c{0xABC4} permet  d'effectuer
  l'envoi:
\begin{lstlisting} 
void send(int data) {
  *0xABC0 = data;
  *0xABC4 = 1;
}
  \end{lstlisting} 
\end{frame} 

\begin{frame}[fragile]{Exemple de ressource partagée}
  Etudions le cas de l'éxecution simultanée de cette fonction par deux
  tâches.  La première tâche appelle \c{send} avec \cmd{data = 42}:
  \begin{lstlisting} 
*0xABC0 = 42
  \end{lstlisting} 
  La  tâche est  préemptée.  La  seconde tâche  appelle  \c{send} avec
  \cmd{data = 10}:
\begin{lstlisting} 
*0xABC0 = 10
*0xABC4 = 1
\end{lstlisting} 
  \c{10} est envoyé. La tâche 1 reprend la main:
\begin{lstlisting} 
*0xABC4 = 1
\end{lstlisting} 
  \c{10} (au lieu de \c{42}) est de nouveau envoyé.\\[3mm]

  Ce cas  est aussi valable dans  le cas d'une  interruption (bien que
  plus rare dans la pratique).
\end{frame} 

\subsection{Réentrance}

\begin{frame}{Comment éviter le problème?}
  Nous devons élargir ce que nous avons précédement vu pour le partage
  d'informations avec les interruptions.

  Les problèmes d'accès concurrents se traduisent très souvent par des
  \emph{races  conditions}.   C'est à  dire  des problèmes  aléatoires
  produit par une séquence particulière d'évènements
  \begin{itemize} 
  \item   Les  \emph{race  conditions}   sont  souvent   difficiles  à
    reproduire et à identifier
  \item Les  \emph{race conditions} peuvent être latente  dans le code
    et se déclarer suite à une modification de l'environnement externe
  \item Une race condition coûte chère (diffuculté de correction, peut
    potentiellement atterrir en production)
  \end{itemize} 
\end{frame}

\begin{frame}{Comment s'en protèger?}
  Comment s'en protèger?
  \begin{itemize} 
  \item  Ne  pas  utiliser  de  variables globales  ou  de  ressources
    partagées
  \item Utiliser des accès atomiques
  \item   Placer  des   accès   aux  ressources   partagée  dans   des
    \emph{sections critiques}
  \end{itemize} 
  Une  fonction  pouvant  être  appellée simultanénement  depuis  deux
  contextes de tâches différentes est dite \emph{réentrante}
\end{frame} 

\begin{frame}{Partage de ressources critiques} 
  Une ressource critique ne peut :
  \begin{itemize}
  \item être utilisée simultanément par plusieurs tâches
  \item être réquisitionnée par une autre tâche
  \end{itemize}
  Notion de section critique :
  \begin{itemize}
  \item  séquence  d'instructions pendant  lesquelles  on utilise  une
    ressource critique \note{hein?}
  \item sans  problème dans le cas d'un  ordonnancement non préemptif,
    mais  c'est rarement  le cas  dans un  environnement temps  réel ⇒
    évaluation du  temps de  réponse très difficile,  sinon impossible
    (abondante littérature !)
  \end{itemize}
\end{frame}

\subsection{Partage de ressource entre deux tâches: Fonctionnement d'un mutex}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Nécessite une instruction assembleur  premettant un accès en lecture
  et une écriture  en une instruction: \texttt{test\_and\_set} affecte
  le registre d'état  en fonction de la valeur  du registre et affecte
  la valeur 1  au registre. On peut développer  la fonction \c{lock} à
  partir de là:
\begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m))
    schedule();
}

void unlock(mutex_t *m) {
  m = 0;
  schedule();
}
\end{lstlisting} 
\end{frame}

\begin{frame}[fragile]{Fonctionnement d'un mutex}
  Un peu mieux:
  \begin{lstlisting} 
void lock(mutex_t *m) {
  while (test_and_set(m)) {
    this_task.reason = m;
    this_task.state = stop;
    schedule();
  }
}

void unlock(mutex_t *m) {
  m = 0;
  foreach (i in tasks)
    if (i.state == stop && i.reason == m)
      i.state = run;
  schedule();
}
  \end{lstlisting}
\end{frame} 

\section{Problème liés aux partage de ressources}

\subsection{Dead Lock}

\begin{frame}[fragile]{Dead lock}
  \begin{itemize} 
  \item Aussi appellé \emph{étreinte fatale}
  \item Deux tâches utilisent  deux ressources imbriquées dans l'ordre
    inverses
  \end{itemize} 
  \begin{columns}
    \begin{column}{5cm}
      Tache 1:
      \begin{lstlisting}[showlines=true,emptylines=10]
lock(m1);



lock(m2);
      \end{lstlisting} 
    \end{column}
    \begin{column}{5cm}
      Tache 2:
      \begin{lstlisting}[showlines=true,emptylines=10]

lock(m2);
// Deadlock ici:
lock(m1);

      \end{lstlisting} 
    \end{column}
  \end{columns}
\begin{center}
  % AABBAXXX
  \begin{tikzpicture}[scale=0.35]
    \timeline{10}{-3.5}{-1.0/A, -2.5/B}
    \fill[color=black!25] (5, -1.5) rectangle +(4, 1);
    \fill[color=black!25] (4, -3.0) rectangle +(5, 1);
    \fill[cgreen] (0,-1.5)  \hi 2 \lo 2 \hi 1 \lo 4;
    \fill[cred]   (0,-3.0)  \lo 2 \hi 2 \lo 1 \lo 4;
    \pattern[pattern=north east lines] (1, -1.5) rectangle +(7, 1);
    \pattern[pattern=north west lines] (3, -3.0) rectangle +(5, 1);
    \pb{0}{-1}{cgreen};
    \pb{2}{-2.5}{cred};
  \end{tikzpicture}
\end{center}
\end{frame} 

\begin{frame}[fragile]{Dead lock}
  \textbf{Remarque:} \\
  Le code suivant:
  \begin{lstlisting} 
lock();
lock(); 
  \end{lstlisting} 
  entraine un  \emph{double lock},  un type particulier  de \emph{Dead
    lock}
\end{frame} 

\begin{frame}[fragile]{Mutex dans une interruption}
  Ne jamais utiliser de mutex dans une interruption.
  \begin{itemize} 
  \item Si  la ressource  est occuppée par  la tâche qui  vient d'être
    préemptée, le \texttt{lock()} s'éxécutera dans le même contexte
  \item[$\rightarrow$] Double lock
  \item De plus,  le blocage d'un mutex peut  entrainer peut entrainer
    une  très  important latance  ce  qui  est  en contradiction  avec
    l'objectif de rester le minimum de temps dans une interruption
  \item[$\rightarrow$] Règle générale: Il ne faut pas appeller \texttt{schedule} dans une interruption.
  \end{itemize} 
\end{frame} 

\subsection{Latence introduite}

\begin{frame}{Latence}
  \begin{itemize} 
  \item  Cas d'une tâche  de faible  priorité utilisant  une ressource
    d'une tâche de haute priorité.
  \item Existe uniquement en environnement préemptif
  \end{itemize} 
  Exemple avec deux tâches $P(A) < P(B)$:
  \begin{itemize} 
  \item Cas sans partage de ressource:
  \begin{columns}
    \begin{column}{6cm}
    % AABBBAAAA
    \begin{center}
    \begin{tikzpicture}[scale=0.35]
        \timeline{10}{-3.5}{-1.0/A, -2.5/B}
         \fill[cgreen] (0,-1.5)  \hi 2 \lo 3 \hi 4 \lo 1;
         \fill[cred]   (0,-3.0)  \lo 2 \hi 3 \lo 4 \lo 1;
         \pb{0}{-1}{cgreen};
         \pb{2}{-2.5}{cred};
     \end{tikzpicture}
   \end{center}
 \end{column}
   \begin{column}{4cm}
 $$TR_B = 3$$
\end{column}
\end{columns}
  \item Cas avec une ressource partagée:
  \begin{columns}
    \begin{column}{6cm}
     % AABAAABBA
    \begin{center}
     \begin{tikzpicture}[scale=0.35]
        \timeline{10}{-3.5}{-1.0/A, -2.5/B}
        \fill[color=black!25] (3, -3.0) rectangle +(3, 1);
        \fill[cgreen] (0,-1.5)  \hi 2 \lo 1 \hi 3 \lo 2 \hi 1 \lo 1;
        \fill[cred]   (0,-3.0)  \lo 2 \hi 1 \lo 3 \hi 2 \lo 1 \lo 1;
        \pattern[pattern=north east lines] (1, -1.5) rectangle +(5, 1);
        \pattern[pattern=north east lines] (6, -3.0) rectangle +(1, 1);
        \pb{0}{-1}{cgreen};
        \pb{2}{-2.5}{cred};
      \end{tikzpicture}
   \end{center}
 \end{column}
   \begin{column}{4cm}
      $$TR_B = 6$$
    \end{column}
  \end{columns}
\end{itemize}     
\end{frame} 

\subsection{Inversion de priorité}

\begin{frame}{Inversion de priorité}
  \begin{itemize} 
  \item Phénomène dû à la présence simultanée de priorités fixes et de
    ressources à accès exclusif dans un environnement préemptif
  \item  Une  tâche  de  priorité  intermédiaire peut  être  élue  par
    l'ordonnanceur  alors  que  des  tâches  de  plus  haute  priorité
    attentent.
  \item Il est diffile de calculer  le temps de blocage des tâches par
    une inversion de priorité (il est généralement non-borné)
  \end{itemize} 
  Cas notable de \emph{Path Finder}
\end{frame}

\begin{frame}{Inversion de priorité}
  \textbf{Exemple:}\\
  On ajoute à l'exemple précédant une  tâche $C$ telle que : 
  $P(B) > P(C) > P(A)$
  \begin{itemize} 
  \item   Cas sans partage de ressource:
    % AABBBBCCCCCCCCCAA
    \begin{center}
      \begin{tikzpicture}[scale=0.30]
           \timeline{16}{-5}{-1./A, -2.5/B, -4./C}
           \fill[cgreen] (0,-1.5)  \hi 2 \lo 4 \lo 9 \hi 2;
           \fill[cred]   (0,-3.0)  \lo 2 \hi 4 \lo 9 \lo 2;
           \fill[cblue]  (0,-4.5)  \lo 2 \lo 4 \hi 9 \lo 2;
           \pb{0}{-1}{cgreen};
           \pb{2}{-2.5}{cred};
           \pb{2}{-4}{cblue};
         \end{tikzpicture}
    \end{center}
  \item   Cas avec un mutex:
    % AABCCCCCCCCCABBBA
    \begin{center}
      \begin{tikzpicture}[scale=0.30]
        \timeline{16}{-5}{-1./A, -2.5/B, -4./C, }
        \fill[color=black!25] (3, -3.0) rectangle +(10, 1);
        \fill[cgreen] (0,-1.5)  \hi 2 \lo 1 \lo 9 \hi 1 \lo 3 \hi 1;
        \fill[cred]   (0,-3.0)  \lo 2 \hi 1 \lo 9 \lo 1 \hi 3 \lo 1;
        \fill[cblue]  (0,-4.5)  \lo 2 \lo 1 \hi 9 \lo 1 \lo 3 \lo 1;
        \pattern[pattern=north east lines] (1, -1.5) rectangle +(12, 1);
        \pattern[pattern=north east lines] (13, -3.0) rectangle +(1, 1);
        \pb{0}{-1}{cgreen};
        \pb{2}{-2.5}{cred};
        \pb{2}{-4}{cblue};
      \end{tikzpicture}
    \end{center}
    La tâche  $C$ s'éxecute alors  qu'elle a une priorité  inféreure à
    $B$ et ne partage aucune ressource avec $B$.
  \end{itemize} 
\end{frame} 

\begin{frame}{Conseils}
  \begin{itemize} 
  \item Essayer de limiter la taille des sections critique
  \item  Essayer  de découper  les  sections  critiques  de manière  à
    favoriser la préemption des tâches de haute priorité
  \item Essayer de  diminuer la granularité des mutex  afin de limiter
    la taille des section critique.
  \end{itemize} 
\end{frame} 

\section{Solutions}

\subsection{Priority inheritence}

\begin{frame}{Héritage de priorité}
  \begin{itemize} 
  \item Aussi appellé \emph{Priority inheritence}
  \item Principe: Si  une tâche bloque une ressource  demandée par une
    tâche  de plus  haute  priorité, elle  acquiert temporairement  la
    priorité de la tâche de haute priorité.
  \item Attention à la gestion de l'héritage en cascade.
  \item  L'algorithme parait  simple,  mais c'est  assez complexe.  Il
    existe même des cas problèmatiques (dont le cout de résolution est
    polynomial)   dans   le   cas   d'architectures   multiprocesseurs
    symétriques sur des \cmd{rw\_lock}.
  \end{itemize} 
  Exemple précédant:
  % AABABBBCCCCCCCCCA
  \begin{center}
    \begin{tikzpicture}[scale=0.30]
      \timeline{16}{-5}{-1./A, -2.5/B, -4./C, }
      \fill[color=black!25] (3, -3.0) rectangle +(1, 1);
      \fill[cgreen] (0,-1.5)  \hi 2 \lo 1 \hi 1 \lo 3 \lo 9 \hi 1;
      \fill[cred]   (0,-3.0)  \lo 2 \hi 1 \lo 1 \hi 3 \lo 9 \lo 1;
      \fill[cblue]  (0,-4.5)  \lo 2 \lo 1 \lo 1 \lo 3 \hi 9 \lo 1;
      \pattern[pattern=north east lines] (1, -1.5) rectangle +(3, 1);
      \pattern[pattern=north east lines] (4, -3.0) rectangle +(1, 1);
      \pb{0}{-1}{cgreen};
      \pb{2}{-2.5}{cred};
      \pb{2}{-4}{cblue};
    \end{tikzpicture}
  \end{center}
\end{frame} 

\begin{frame}{Héritage de priorité}
  Autre exemple:
  Soit 3 tâches et 2 ressources telle que A et B partage la première ressource et B et C partage la seconde:
  $$P(A) > P(B) > P(C)$$
  % CCBBCACBABC  
  \begin{center}
    \begin{tikzpicture}[scale=0.5]
      \timeline{11}{-5}{-1./A, -2.5/B, -4./C, }
      \fill[color=black!25] (6, -1.5) rectangle +(2, 1);
      \fill[color=black!25] (3, -3.0) rectangle +(4, 1);
      \fill[cgreen] (0,-1.5)  \lo 2 \lo 2 \lo 1 \hi 1 \lo 1 \lo 1 \hi 1 \lo 1 \lo 1;
      \fill[cred] (0,-3.0)  \lo 2 \hi 2 \lo 1 \lo 1 \lo 1 \hi 1 \lo 1 \hi 1 \lo 1;
      \fill[cblue] (0,-4.5)  \hi 2 \lo 2 \hi 1 \lo 1 \hi 1 \lo 1 \lo 1 \lo 1 \hi 1;
      \pattern[pattern=north east lines] (1, -4.5) rectangle +(6, 1);
      \pattern[pattern=north east lines] (7, -3.0) rectangle +(3, 1);
      \pattern[pattern=north west lines] (3, -3.0) rectangle +(5, 1);
      \pattern[pattern=north west lines] (8, -1.5) rectangle +(1, 1);
      \pb{5}{-1}{cgreen};
      \pb{2}{-2.5}{cred};
      \pb{0}{-4}{cblue};
    \end{tikzpicture}
  \end{center}
\end{frame} 

\begin{frame}{Héritage de priorité} 
  Concernant le temps de réponse  des tâches dans un système intégrant
  l'héritage de priorité:
  \begin{itemize}
  \item Le  temps de blocage $B_i$  d'une tâche de  haute priorité par
    une tâche de plus basse priorité nominale est borné
  \item ...  mais le calcul de  ce temps de blocage  maximum peut être
    très complexe
  \item Condition nécessaire d'ordonnançabilité par un algorithme Rate
    Monotonic :
    $$\forall i \in tasks \left( \sum_{k = 1..i} \frac{C_k}{T_k} \right) + \frac{B_i}{T_i} ≤ i(2^{1/i} - 1)$$
  \end{itemize}
\end{frame}

\begin{frame}{Problème rémanent} 
  \begin{itemize}
  \item Blocages en chaîne (cf notre exemple avec 3 tâches)
  \item Deadlock
  \end{itemize}
\note{Ajouter deux exemples?}
\end{frame}

\subsection{Priority ceilling}

\begin{frame}{Priorité plafonnée}
  \begin{itemize} 
  \item Aussi appellée \emph{Priority ceilling}
  \item Introduit  à la  fin des années  80 pour résoudre  le problème
    d'inversion de priorité tout en prévenant l'occurence de deadlocks
    et de blocages en chaîne
  \item Amélioration  du protocole d'héritage de priorité  : une tâche
    ne peut pas entrer dans une section critique s'il y a un sémaphore
    acquis qui pourrait la bloquer
  \item Principe : on attribue à chaque sémaphore une priorité plafond
    égale  à  la  plus   haute  priorité  des  tâches  qui  pourraient
    l'acquérir. Une  tâche ne pourra  entrer dans la  section critique
    que si  elle possède une  priorité supérieure à toutes  celles des
    priorités plafond des sémaphores acquis par les autres tâches
  \end{itemize} 
\end{frame} 

\begin{frame}{Algorithme}
  \begin{itemize} 
  \item  On attribue  à chaque  sémaphore $S_k$  une  priorité plafond
    $C(S_k)$ égale à la plus haute priorité des tâches susceptibles de
    l'acquérir
  \item Soit $i$  la tâche prête de plus  haute priorité : l'accès
    au processeur est donné à $i$
  \item soit $S*$ le sémaphore dont la priorité plafond $C(S*)$ est la
    plus grande parmi  tous les sémaphores déjà acquis  par des tâches
    autres que $i$
  \item Pour entrer dans une  section critique gardée par un sémaphore
    $S_k$, $i$ doit avoir une  priorité supérieure à $C(S*)$. Si $P_i
    ≤ C(S*)$,  l'accès à $S_k$  est interdit et  on dit que  $i$ est
    bloquée sur $S*$ par la tâche qui possède $S*$
  \end{itemize} 
\end{frame} 

\begin{frame}{Exemple}
  \begin{center}
    \begin{tabular}{ccccc}
      \hline
      Tâche & Arrivée & Priorité & Capacité & Ressources \\
      \hline
      A & 4 & 1 & 5 & \texttt{\_\_12\_}\\
      B & 2 & 2 & 4 & \texttt{\_22\_}\\
      C & 2 & 3 & 2 & \texttt{\_\_}\\
      D & 0 & 4 & 6 & \texttt{\_1111\_}\\
      \hline
    \end{tabular}
  \end{center}
  Les priorités plafond sont donc: 
  \begin{itemize}
  \item $C(S_1) = P_A$ 
  \item $C(S_2) = P_A$ 
  \end{itemize}
\end{frame} 

\begin{frame}{Sans mécanisme de protection}
  \input{pics/prio-inherit-1.tex}
\end{frame} 

\begin{frame}{Par héritage de priorité}
  \input{pics/prio-inherit-2.tex}
\end{frame} 

\begin{frame}{Par priorité plafonnée originale}
  \input{pics/prio-inherit-3.tex}
\end{frame} 

\begin{frame}{Par priorité plafonnée immédiate}
  \input{pics/prio-inherit-4.tex}
\end{frame} 

% \begin{frame}{Priorité plafonnée} 
%   \begin{itemize}
%   \item à t = 0, T2 est activée et démarre.
%   \item à t =  1, Le sémaphore S2 est demandé et  obtenu (il n'y a pas
%     d'autre ressource en cours d'utilisation)
%   \item à t = 2, T1 est activée et préempte T2
%   \item à t = 3, T1 demande  S2 et est bloquée par le protocole car la
%     priorité de T1 n'est pas supérieure à la priorité plafond $C(S2)=P1$
%     (S2 est le seul sémaphore acquis à t2) T2 hérite de la priorité de
%     T1 et redémarre
%   \item à t  = 4, T2 demande  et obtient le sémaphore S1  , car aucune
%     autre tâche ne détient de ressource
%   \item à t = 5 T0 est réveillée et préempte T2
%   \item  à t =  6, T0  demande le  sémaphore S0  qui n'est  détenu par
%     aucune autre tâche. Le protocole  bloque néanmoins T0 parce que sa
%     priorité n'est  pas supérieure à  la plus grande  priorité plafond
%     des sémaphores  déjà détenus  (S2 et  S1) : P0.   T2 hérite  de la
%     priorité de T0 et peut redémarrer
%   \item à t = 7 , T2 relâche S1. Sa priorité p2 est ramenée à P1, plus
%     haute priorité des tâches bloquées par T2. T0 peut alors préempter
%     T2 et acquérir S0
%   \item à t = 9 quand T0 demande S1, le seul sémaphore encore tenu est
%     S2 avec  une priorité plafond  $P1 \leftarrow T0$ (priorité  $P0 >
%     P1$) obtient S1
%   \item à  t =  10, T0  se termine. T2  peut reprendre  son exécution,
%     toujours avec la même priorité P1
%   \item à t =  11, T2 relâche S2. Sa priorité est  ramenée à sa valeur
%     nominale P2. T1 peut alors préempter T2 et redémarrer
%   \item à t = 12, T1 se termine, T2 peut redémarrer et se terminer
%   \end{itemize}
% \end{frame}

% \begin{frame}{Autre Exemple}
%   Par héritage de priorité
%   % CCBBACCAABAABC
%   \begin{center}
%     \begin{tikzpicture}[scale=0.5]
%       \timeline{14}{-5}{-1./A, -2.5/B, -4./C, }
%       \fill[cgreen]  (0,-1.5) \lo 2 \lo 2 \hi 1 \lo 2 \hi 2 \lo 1 \hi 2 \lo 1 \lo 1;
%       \fill[cred]    (0,-3.0) \lo 2 \hi 2 \lo 1 \lo 2 \lo 2 \hi 1 \lo 2 \hi 1 \lo 1;
%       \fill[cblue]   (0,-4.5) \hi 2 \lo 2 \lo 1 \hi 2 \lo 2 \lo 1 \lo 2 \lo 1 \hi 1;
%       \pb{0}{-1}{cgreen};
%       \pb{2}{-2.5}{cred};
%       \pb{4}{-4}{cblue};
%       \pattern[pattern=north east lines] (1, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (7, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (4, -4.5) rectangle +(2, 1);
%       \pattern[pattern=north west lines] (3, -3.0) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (9, -3.0) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (10, -1.5) rectangle +(1, 1);
%     \end{tikzpicture}
%   \end{center}
% \end{frame} 

% \begin{frame}{Autre Exemple}
%   Par priorité plafonnée:
%   % CCBCACAAAABBBC
%   \begin{center}
%     \begin{tikzpicture}[scale=0.5]
%       \timeline{14}{-5}{-1./A, -2.5/B, -4./C, }
%       \fill[cgreen]  (0,-1.5) \lo 2 \lo 1 \lo 1 \hi 1 \lo 1 \hi 4 \lo 3 \lo 1;
%       \fill[cred]    (0,-3.0) \lo 2 \hi 1 \lo 1 \lo 1 \lo 1 \lo 4 \hi 3 \lo 1;
%       \fill[cblue]   (0,-4.5) \hi 2 \lo 1 \hi 1 \lo 1 \hi 1 \lo 4 \lo 3 \hi 1;
%       \pb{0}{-1}{cgreen};
%       \pb{2}{-2.5}{cred};
%       \pb{4}{-4}{cblue};
%       \pattern[pattern=north east lines] (1, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (3, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (5, -4.5) rectangle +(1, 1);
%       \pattern[pattern=north east lines] (6, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (8, -1.5) rectangle +(1, 1);
%       \pattern[pattern=north west lines] (10, -3.0) rectangle +(2, 1);
%     \end{tikzpicture}
%   \end{center}
% \end{frame} 

\begin{frame}{Priorité plafonnée} 
  On a  le même critère d'ordonnançabilité  par RM que dans  le cas du
  protocole d'héritage de priorité:
  $$\forall i \in tasks \left( \sum_{k = 1..i} \frac{C_k}{T_k} \right) + \frac{B_i}{T_i} ≤ i(2^{1/i} - 1)$$
  mais le calcul du temps de  blocage maximum de chaque tâche est plus
  simple :
    \begin{itemize}
    \item on  peut démontrer  que le temps  de bloquage  maximum $B_i$
      d'une tâche  $i$ est la durée  de la plus  longue des sections
      critiques ($\max D_{j,k}$) parmi celles appartenant à des tâches
      de  priorité inférieure à  $P_i$ et  gardées par  des sémaphores
      dont la priorité plafond est supérieure ou égale à $P_i$
      $$B_i = \max D_{j,k} | P_j < P_i, C(S_k) ≥ P_i$$ 
    \end{itemize}
\end{frame}

\section{Autres mécanismes de gestion d'accès concurrents}

\subsection{Désactivation de l'ordonnanceur}

\note{Pour chacun  des mécanisme,  donner les fonction  dasn plusieurs
  API,  faire  un exemple  ou  mieux,  donner  le code:  Posix,  Java,
  Xenomai, ucosII, vxWorks}

\subsection{Sémaphore}

\begin{frame}{Sémaphore}
  \begin{itemize} 
  \item  Différence entre un  mutex et  un semaphore  binaire: presque
    aucune.
  \item Parfois le sémaphore  binaire est utilisé pour implémentéer le
    mutex.
  \item Toutefois,  d'un point de  vue sémantique, on pourrait  que le
    mutex  permet  d'avoir un  morceau  de  code mutuelement  exclusif
    tandis que  le sémaphore est  une section de  code limité à  uen 1
    ressource.
  \item  Notons  aussi  que  les  algorithme  d'héritage  de  priorité
    néxistent pas sur les sémaphores
  \end{itemize} 
\end{frame} 

\subsection{Mutex réentrant}

\begin{frame}{Mutex Réentrant}
  \begin{itemize} 
  \item Idem  mutex, mais  si la même  tâche tente de  revérouiller le
    même mutex, le mutex est non-bloquant.
  \item Dans le cas  d'un mutex non-réentrant, ceci entraine forcement
    un dead-lock.
  \item  Un sémaphore est maintenu pour connaitre le
    nombre de passage.
  \end{itemize} 
\end{frame} 

\subsection{R/W Lock}

\begin{frame}[fragile]{Read/Write Lock}
\note{\url{http://en.wikipedia.org/wiki/Readers-writers\_problem}}

Permet de limiter le phénomène  de latence en dimiminuant le nombre de
sections critiques.

Solution 1 (\emph{reader preference}):
\begin{columns}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_lock() {
  // mutex protege read_count
  lock(mutex);
  readcount++;
  if (readcount == 1)
    lock(w);
  unlock(mutex);
}
    \end{lstlisting} 
  \end{column}
  \begin{column} {5cm}
    \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount = 0)
    unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(w);
}
void write_unlock() {
  unlock(w);
}
    \end{lstlisting} 
  \end{column}
\end{columns}
\end{frame} 

\begin{frame}[fragile]{Read/Write Lock}
  Problème: un accès en écriture doit attendre que toutes les lectures
  soient terminées. Solution 2 (\emph{writer preference}):
  \begin{columns}
    \begin{column} {5cm}
      \begin{lstlisting} 
void read_lock() {
  lock(r);
  lock(mutex);
  readcount++;
  if (readcount == 1)
     lock(w);
  unlock(mutex);
  unlock(r);
  // r n'est pas bloque durant la lecture
}
       \end{lstlisting} 
     \end{column}
     \begin{column} {5cm}
       \begin{lstlisting} 
void read_unlock() {
  lock(mutex);
  readcount--;
  if (readcount == 0)
     unlock(w);
  unlock(mutex);
}
void write_lock() {
   lock(r);
   lock(w);
}
void write_unlock() {
  unlock(w);
  unlock(r);
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\subsection{Rendez-vous ou barrier}
\begin{frame}[fragile]{Rendez-vous}
  Permet de synchroniser  deux tâches. La première tâche  arrivée à la
  barrière attend la seconde.
\begin{lstlisting} 
void init() {
  lock(m1);
  lock(m2);
}
\end{lstlisting}
Tâche 1:
\begin{lstlisting} 
  unlock(m1);
  lock(m2);
\end{lstlisting} 
Tâche 2:
\begin{lstlisting} 
  unlock(m2);
  lock(m1);
\end{lstlisting} 
\end{frame}

\subsection{Condition}

\begin{frame}[fragile]{Conditions}
  Peut être  considéré comme des \emph{rendez-vous} à  sens unique. Si
  une  tâche attend,  elle  est débloquée,  sinon,  aucun effet.  Très
  utilisée pour le pattern des \cmd{work-thread}
  \begin{columns}
    \begin{column}{5cm}
      \begin{lstlisting} 
void init() {
  lock(m);
}

void wait() {
  lock(m);
}

void signal() {
  unlock(m);
  try_lock(m);
}
      \end{lstlisting}
    \end{column}
    \begin{column}{5cm}
      \begin{lstlisting} 
// broadcast debloque tous les 
// waiters que alors signal en 
// debloque uniquement un
void broadcast()  {
  // Plus complexe, il faut 
  // un mutex par waiters. 
}
      \end{lstlisting} 
    \end{column}
  \end{columns}
\end{frame} 

\subsection{Buffer circulaire et Queue}

\begin{frame}[fragile]{Buffer circulaire et Queue}
  \begin{itemize} 
  \item  Précédement décrit dans  la section  ``Partage d'informtaiton
    avec les interruptions''
  \item Fonctionne aussi très bien entre les tâches
  \item Une  des rare structure  permettant d'être paratgée à  la fois
    avec une interruption et des tâches
  \item Faire attention à l'allocation dynamique des objets
  \end{itemize}
\end{frame} 

\subsection{Spin Lock, Mutex et désactivation des interruptions}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  Lorsque:
  \begin{itemize} 
  \item  Vos  sections critique  font  intervenir  des  tâches et  des
    interruptions
  \item Votre problème ne concerne  pas un échange de données (et donc
    le buffer circulaire n'est pas une solution)
  \item Vous ne pouvez pas faire autrement
  \end{itemize} 
  alors,   vous  devez   combiner  les   trois   mécanismes  suivants:
  Désactivation des interruptions, Mutex et Spin Lock.

  Le point sur ces trois mécanismes:
  \begin{itemize} 
  \item  Si  une  ressource  est   partagé  entre  une  tâche  et  une
    interruption sur  le même coeur,  il est nécessaire  de désactiver
    les interruptions
  \item  Si une ressource  est partagé  entre deux  tâche sur  un même
    coeur, il est nécessaire d'utiliser un mutex
  \item Si  la ressource est  partagée avec un  autre coeur et  que le
    temps d'utilisation est court, utilisez un Spin Lock.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Spin Lock, Mutex et désactivation des interruptions}
  On pourrait imaginer un cas cimmulant les trois contraintes:
  \begin{lstlisting} 
disable_interrupts()
mutex_lock(m)
spin_lock(s)
a++
spin_unlock(s)
mutex_unlock(m)
enable_interrupts()
  \end{lstlisting} 
  Globalement, évitez!
\end{frame} 

\subsection{Algorithmes non-bloquants}

\begin{frame}{Algorithmes non-bloquants}
  \begin{itemize} 
  \item Algorithme thread-safe n'utilisant pas de sections ciritques. 
  \item Ces  algorithmes utilisent souvant  des instructions atomiques
    proposés par certains processeurs
  \item Par conséquant, ils sont peu portables
  \item Souvent utilisé dans les base de données
  \end{itemize} 
\end{frame} 

\subsection{RCU}
\begin{frame}[fragile]{Read-Copy-Update}
Type d'algorithme non bloquant

Particulièrement utile pour les manipulation de listes:
\begin{lstlisting} 
typedef struct {
   struct a_t a;
   int count_usage = 0;
   bool obsolete = false;
} rcu_t;
rcu_t *a = malloc(sizeof(rcu_t)); 

void read_a() {
  // lock:
  rcu_t *ptr = a;
  ptr->count_usage++;

  // do something with ptr;

  // unlock:
  ptr->count_usage--;
  if (ptr->obsolete && ! ptr->count_usage)
    free(ptr);
}

void write_a() { 
   struct rcu_t *a3 = a;
   struct rcu_t *a2 = malloc(sizeof(rcu_t));
   memcpy(a2, a);
   // modify a2;   
   a = a2;  
   a3->obsolete = true;
   if (!a3->count_usage)
      free(ptr);
}
\end{lstlisting} 
\end{frame} 

% fg/bg, intertuptions, etc... désactivation des interruption. 

\part{Le multitâches}

\section{Fonctionnement monotâches}

\begin{frame}{Quelques définitions}
  \begin{itemize}
  \item \textbf{Temps de réponse} : temps entre un évènement et la fin
    du traitement de l'évènement.
  \end{itemize} 
\end{frame}

\subsection{Par scrutation des évènements}
\begin{frame}[fragile]{Scrutation des évènements}
  \begin{itemize} 
  \item Aussi appellé \emph{polling}
  \item Boucle infinie 
  \item On teste des valeurs des entrées à chaque tour de boucle
  \end{itemize} 
  \begin{lstlisting} 
#define sensor1 *((char *) 0x1234)
#define sensor2 *((char *) 0xABCD)

int main() {
  while (1) {
    if (sensor1)
      action1();
    if (sensor2)
      action2();
  }
}
  \end{lstlisting} 
\end{frame}

\begin{frame}{Scrutation}
  \begin{itemize} 
  \item Temps de réponse au  évènements en pire cas facile à calculer:
    Pire temps pour parcourir la boucle
  \item Utilisation du CPU sous optimal. Beaucoup de temps est utilisé
    pour lire la valeur des  entrée. Ceci est particulièrement vrai si
    les évènements sont peu fréquents
  \item Si certains évènements entrainent des temps de traitement long
    ou si il y a beaucoup  d'entrées à scruter, le temps de réponse en
    pire cas peut rapidement devenir très grand
  \end{itemize} 
\end{frame} 

\subsection{Gestion d'interruptions synchrones} 

\begin{frame}{Interruptions synchrones}
  \begin{itemize} 
  \item Appellé aussi Background/Foreground
  \item Gestion des évènements dans les interruptions
  \end{itemize} 
  \begin{center}
    \pgfimage[width=6cm]{model_bgfg.png}
  \end{center}
\end{frame}

\begin{frame}[fragile]{Interruptions synchrones}
  Concrètement:
  \begin{lstlisting}
#define sensor1 *((char *) 0x1234)

void interrupt() {
  action1();
}

int main() {
  enable_interrupt(interrupt, 0x1);
  while(1) {
// Optionnal background computing 
  }
}
  \end{lstlisting} 
\end{frame}

\begin{frame}{Interruptions synchrones}
  \begin{itemize} 
  \item Temps de réponse au évènements plutôt bon
  \item Temps de réponse assez simple à calculer. Somme de 
    \begin{itemize}
    \item Temps de traitement de l'évenement
    \item Temps de traitement des évènemnts de priorité supérieures
    \item Temps du changement de contexte (plus ou moins constant)
    \item Pire interval de temps ou les interruptions sont désactivée 
    \end{itemize} 
  \item[$\rightarrow$] Dans un système simple, ça peut se calculer à la louche
  \end{itemize} 
\end{frame} 

\begin{frame}{Qu'est-ce qu'une interruption?}
  Il existe trois type d'interruptions:
  \begin{itemize} 
  \item Les interrruption matérielles:
    \begin{itemize} 
    \item IRQ (aussi appellé Interruption externe). Asynchrone. Exemples: clavier, horloge, bus, DMA, second processeur, etc...
    \item Exception.  Asynchrone ou Synchrone.  Exemples: Division par
      zéro,   Erreur   arithmétique,   Erreur  d'instruction,   Erreur
      d'alignement, Erreur de page, Breakpoint matériel, Double faute,
      etc...
      \note{Une overflow  arithmétique ne produit  pas d'exception, il
        lève le flags ``retenue''}
      \note{Un  breakpoint  logiciel change  une  instruction par  une
        interruption  logicielle. Un  break point  software  n'est pas
        possible en ROM alors que le breakpoint hardware oui}
    \end{itemize} 
  \item Logicielle. Déclenché par une instruction. Synchrone.
  \end{itemize}
\end{frame} 

\begin{frame}{Fonctionnement d'une interruption}
  Quand une  interruption est levée:
  \begin{itemize} 
  \item le CPU sauve en  partie ou en totalité le contexte d'execution
    (principalement le pointeur d'instruction) sur la pile
  \item Le CPU passe en mode superviseur (nous y reviendrons)
  \item il recherche dans  l'IVT (Interrupt Vector Table aussi appellé
    IDT,  Interrupt  Description  Table) l'ISR  (Interruption  Service
    Routine) associée
  \item Le CPU place le pointeur d'instruction sur l'ISR
  \item  L'ISR traitement  l'évènement (fin  de traitement  d'une E/S,
    etc...)
  \item L'ISR acquite la  réception de l'interruption indiquant qu'une
    nouvelle  donnée peut-être  traitée.
  \item L'ISR restore le (un) contexte
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Fonctionnement d'une interruption} 
  \begin{center}
    \pgfimage[width=10cm]{interuption-1.png}
  \end{center}
\end{frame}  

\begin{frame}{Fonctionnement d'un PIC}
  Le PIC (Programmable Interrupt Controller) est un composant matériel
  permettant  la gestion  des  IRQ.  Il peut-être  intégré  au CPU  ou
  externe (ou à cheval entre les deux...). Il permet en particulier:
  \begin{itemize}
  \item Activer ou de désactiver des IRQ
  \item De masquer temporairement une IRQ
  \item De mettre en queue une interruption temporairement masquée
  \item De controller la priorité des interruptions
  \end{itemize} 
  Il arrive fréquement  qu'un PIC soit multiplexé sur  une seule ligne
  d'IRQ. Dans  ce cas, le premier  étage d'ISR lit un  registre du PIC
  pour connaitre  le numéro de l'IRQ.   (Cas notoire du  8259A sur les
  architecture x86)

  \note {Il existe aussi des APIC (Advanced PIC). Sur PC notament}
\end{frame} 

\begin{frame}{Exemple}
  Exemple classique d'intégration d'un PIC avec multiplexage sur un IRQ:
  \begin{center}
    \pgfimage[width=10cm]{interuption-3.png}
  \end{center}
\end{frame} 

\begin{frame}{Exemple}
  \begin{enumerate}
  \item Le périphérique \emph{Timer} lève sa ligne d'IRQ
  \item Le PIC recoit l'interruption et lève une IRQ du processeur
  \item  Le processeur  complète  l'instruction courante  et sauve  le
    registre d'instruction (PC) et le registre d'état (PSW)
  \item La tâche courante devient interrompue
  \item Le premier étage d'ISR est appellé
  \item  Le  gestionnaire d'interruption  complète  la sauvegarde  des
    registres
  \item   Le  gestionnaire  d'interruption   demande  au   PIC  quelle
    interruption à  été appellée et il  lit dans l'IVT  quelle ISR est
    associée
  \end{enumerate}
\end{frame}

\begin{frame}{Exemple}
  \begin{enumerate}
  \item Le  gestionnaire d'interruption se branche  sur l'ISR associée
    (ici, ISR1)
  \item L'IRQ du processeur est  acquitée. Les autre IRQ peuvent ainsi
    être levées
  \item L'ISR1 lit lit la  valeur provenant du \emph{Timer} et acquite
    l'interruption  du \emph{Timer}. Ce  périphérique peut  de nouveau
    lever des IRQ.
  \item Les registres généraux sont restaurés
  \item Le contexte d'éxecution est restauré
  \item Le registre PC est restauré
  \end{enumerate}
\end{frame} 

\begin{frame}{Exemple}
  Exemple de différence d'approche entre la gestion par scrutation et 
  la gestion par interruption:\\

  Prennons  l'acquisition  de   donnée  à  partir  d'un  convertisseur
  analogique/numérique asynchrone
  \begin{itemize}
  \item  Dans  le  cas  du  traitement  par  scrutation,  nous  allons
    periodiquement voir  si un résultat est arrivé.  Beaucoup de temps
    est  consommé  pour  rien   et  lorsque  le  résultat  arrive,  le
    traitement du résultats sera retardé
  \item  Une interruption  est  levée quand  une  nouvelle donnée  est
    disponible. Le processeur peut alors la traiter.
  \end{itemize}
\end{frame} 

\begin{frame}{Latence des interruptions}
  \begin{itemize} 
  \item Un périphérique  en doit pas regénérer d'IRQ  si la précédante
    n'est pas acquitée
  \item  Vu les que  les interruptions  sont souvent  multiplexée, les
    sont souvent  désactivées lors de la première  phase de traitement
    des interruptions
  \item Il est parfois nécessaire de désactiver les interruptions 
  \item  Le partage  de l'information  entre les  interruptions  et le
    reste   du   programme  nécessite   parfois   de  désactiver   les
    interruptions (Nous y reviendrons)
  \end{itemize} 
  Les conséquences:
  \begin{itemize} 
  \item Augmente le temps de réponse
  \item  Risque   de  perdre  des  interruption  (Dans   ce  cas,  une
    interruption \emph{overrun} est (devrait être) déclenchée)
  \end{itemize} 
\end{frame} 

\begin{frame}{Precautions avec les interruption}
  \begin{itemize} 
  \item Acquiter l'interruption le plus tot possible
  \item Rester le moins de temps possible dans dans une interruption
  \item Accèder à un minimum de données pour eviter d'avoir à partager
    des données avec le background
  \item Transferer un maximum de traitement hors de l'interruption
  \item[$\rightarrow$] Gestion des interruption asynchrone
  \end{itemize} 
\end{frame} 

\subsection{Gestion d'interruptions asynchrones} 

\begin{frame}[fragile]{Interruptions asynchrones}
  \begin{itemize} 
  \item Interruption séparée en deux parties: \emph{top half} et \emph{bottom half}
  \item On délègue le maximum de traitement au \emph{bottom half}
  \item Permet de décharger les interruptions
  \end{itemize}
  \begin{lstlisting} 
#define sensor1 *((char *) 0x1234)

int gotit = 0;
void interrupt() {
    gotit++;
}

int main() {
  enable_interrupt(interrupt, 0x1);
  while(1) {
     if (gotit) {
       gotit--;
       action1();
     }
// Optionnal background computing 
  }
}
  \end{lstlisting} 
  \note{Il y a un bug à cause du partage de gotit, mais on en parlera plus tard}
\end{frame} 

\begin{frame}[fragile]{Partage d'information avec une interruption}
  \note{Je suis embêté. Est-ce que je triate ca ici moi?}
  \begin{lstlisting} 
int data = 0;
void isr() {
  data++;
  *PTR_DEVICE_ACK = 1;
}

void main() {
  for (;;) {
    if (data) {
      printf("Interrupt\n");
      data--;
    }
// Optionnal background computing 
  }
}
  \end{lstlisting} 
\end{frame} 

\begin{frame}{Partage de l'information}
  Partage d'information avec des interruptions:
  \begin{itemize} 
  \item  operation atomique
  \item  buffer ciculaires et queue
  \item  désactivation des interruptions
  \end{itemize} 
  \begin{itemize} 
  \item Utilisation de structures de partage de données sans mutex: buffer circulaire et queue
  \item Les sections critiques  doivent être faites en désactivant les
    interruption (attention à la lattence induite, cf slide précédant)
  \end{itemize} 
\end{frame} 

\begin{frame}{Cas des interruption en milieu multi coeur}
  \begin{itemize} 
  \item On ne désactive que les interruption locale
  \item Une interruption peut se produire sur un autre coeur
  \item Nécessité d'utiliser un mécanisme supplémentaire d'exclusion
  \item \emph{Spin lock} suvent utilisé pour ce cas.
  \item  Pas  beaucoup  d'autres  choix.  Par  conséquent  les  sections
    critiques dans les interruptions doivent être très limitées
  \end{itemize} 
\end{frame} 

\begin{frame}{Problèmes de la gestion des interruption asynchrone}
  Nous n'avons pas résolu notre problème récurent:
  \begin{itemize} 
  \item  Le partage  de l'information  entre les  interruptions  et la
    boucle principale entraine des latences
  \end{itemize} 
  On retrouve certains problèmes que l'on avait avec la scrutation:
  \begin{itemize} 
  \item Ne permet pas de prioriser les traitement dans la boucle principale
  \item Interaction entre les évènements complexe
  \end{itemize} 
\end{frame} 

\subsection{Le temps partagé}

\begin{frame}{Concurence}
  Des tâches concurente sont  des tâches éxécutée séquentiellement sur
  un seul processeur en entrelacant l'éxécution de chaque tâches.

  La programmation concurente N'EST  PAS de la programmation parallèle
  (même les système multicoeur sont souvent concurent et parallèle):
  \begin{center}
    \pgfimage[width=10cm]{concurentVsParallel.png}
  \end{center}

  Pour les tâches,  le temps partagé est transparent.  Chaque tâche à
  l'impression d'avoir le CPU pour elle-seule.

  On trouvera aussi les terme de multitâche ou de \emph{temps partagé}.
\end{frame} 

\begin{frame}{Taches concurentes}
  Pour les  systèmes plus complexe ou pour  facilité la réutilisation,
  un   système   multitâche   est   plus   approprié   qu'un   système
  \emph{Foreground/Background}.
  \begin{itemize} 
  \item Permet de prioriser les traitements
  \item Facilite la gestion des évènements
  \end{itemize} 
\end{frame} 

\begin{frame}{Concurence}
  Migration d'un système avec gestion asynchrone des interruption vers
  un système multitâches:
  \begin{center}
    \pgfimage[width=10cm]{model_multitask.png}
  \end{center}
\note{Parler des différentes états des tâches ici}
\end{frame} 

\begin{frame}{Le changement de contexte}
  Chaque tâche possède une pile en mémoire. Une liste globale contient:
  \begin{itemize} 
  \item les état de toute les tâches
  \item l'emplacement de la pile en mémoire
  \item le contexte d'éxecution, c'est-à-dire une sauvegardes registres
  \end{itemize} 
  Lors du changement de contexte
  \begin{itemize} 
  \item  on  sauvegarde  le   contexte  de  la  tâche  précédante,  en
    particulier son pointeur de pile et son pointeur d'instruction
  \item on restaure le contexte de la nouvelle tâche
  \item on restore le pointeur d'instruction
  \end{itemize} 
  Dans  la pratique, il  y a  des petites  subtilités dependant  de la
  manière dont le changement de contexte à été amené.
\end{frame} 

\begin{frame}{Multitâche non-préemptif}

  Le changement de contexte  peut-être volontaire par les tâches. Dans
  ce   cas,  la   tâcha   ayant  terminé   son  traitement   appellera
  explicitement   la  fonction   \emph{schedule}   qui  effectura   la
  changement  de   contexte.  le  système  est   dit  non-péemptif  ou
  multitache collaboratif.


  Ce type  de système implique une  latence difficilement quantifiable
  entre un évènement et sont traitement:
  \begin{center}
    \pgfimage[width=10cm]{preemptive-no.png}
  \end{center}
  \begin{enumerate} 
  \item  Une tâche  non prioritaire  est en  cours d'éxecution  et est
    interrupue par un évènement (une IRQ)
  \item L'ISR est appellé
  \item Le traitement  l'IRQ rend une tâche de  haute priorité prête à
    être éxécutée
  \item  A  la fin  de  l'ISR,  le système  rend  le  CPU  à la  tâche
    non-prioritaire
  \item Quand  la tâche non-prioritaire termine  sont traitement, elle
    appelle \texttt{schedule}
  \item L'ordonnaceur donne la main à la tâche de forte priorité
  \item La tâche de haute priorité peut (enfin) s'éxécuter
  \end{enumerate} 
\end{frame} 

\begin{frame}{Multitâche préemptif}
  Un  système  multitâche préemptif  va  être  capable  de changer  de
  contexte lors des interruptions:
  \begin{center}
    \pgfimage[width=10cm]{preemptive-yes.png}
  \end{center}
  \begin{enumerate} 
  \item  Une tâche  non prioritaire  est en  cours d'éxecution  et est
    interrupue par un évènement (une IRQ)
  \item L'ISR est appellé
  \item Le traitement  l'IRQ rend une tâche de  haute priorité prête à
    être éxécutée
  \item A la fin de l'ISR, le système appelle le scheduler
  \item Le scheuler donne la main a la tâche de haute priorité
  \item  Quand  la tâche  prioritaire  termine  sont traitement,  elle
    appelle \texttt{schedule}
  \item   Vu  qu'il  n'y   a  plus   tache  prioritaire   à  éxecuter,
    l'ordonnaceur redonne la main à la tâche de faible priorité
  \end{enumerate} 
\end{frame} 

\begin{frame}{Le changement de contexte sur interruption}
  \begin{center}
    \pgfimage[width=10cm]{interuption-2.png}
  \end{center}
\end{frame} 

\begin{frame}[fragile]{Round robin}
  Examinons  le cas de  deux tâches  de priorité  équales n'effectuant
  jamais de relanchement volontaire:
  \begin{lstlisting} 
task1() {
  for(;;) ;
}
task2() {
  for(;;) ;
}
\end{lstlisting} 
Dans ce cas, si aucune interruption ne se produit, la premiere tâche à
avoir pris la main ne la  rendra jamais. Afin de reprendre la main, on
utilise une  interruption d'horloge.  Celle-ci garanti que  le système
pourra  périodiquement reordonnacer les  tâche. La  periode l'horologe
utilisé est appelle quantum de temps ou HZ dans le cas de Linux.

Dans ce cas-ci, l'ordonnanceur  devra donner un période à \emph{task1}
puis une  période à  \emph{task2} et ainsi  de suite.  Ce comportement
s'apelle \emph{Round-Robin} ou \emph{Tourniquet}.
\end{frame} 

\subsection{Pagination de la mémoire}

\begin{frame}{La MMU}
  Le temps partagé  permet de simuler que chaque tâche  est la seule à
  utiliser le CPU.

  En revanche, la mémoire est partagée entre les tâches. Ainsi, si une
  tâche A écrit par erreur sur l'espace d'une tâche B:
  \begin{itemize} 
  \item  La tâche B plante
  \item  Le problème est complexe à trouver
  \item Il  n'y a  aucune moyen  pour empêcher la  tâche A  de faire
    cette action.
  \end{itemize} 
\end{frame}

\begin{frame}{La MMU}  
  Les  CPU  modernes  intègrent   un  composant  appellé  MMU  (Memory
  Management Unit):
  \begin{itemize}
  \item  Unite de translation d'addresse mémoire
  \item  On parle d'addresses physiques et virtuelles
  \item Lorsque le MMU est  actif (normalement, tout le temps), toutes
    les addresses du code assembleur sont des addresse virtuelles
  \item  Il est  posisble de  configurer le  MMU avec  une instruction
    spéciale et  en lui  donnant un pointeur  sur un tableau  (dans la
    pratique,  il s'agit  plutot d'un  arbre) associant  les addresses
    physique et les addresse virtuelle
  \item  Il est  possible  de changer  les  association simplement  en
    chargeant une pointeur sur une autre table
  \item On  défini alors une table  par tâche.  Lors  du changement de
    contexte, on change aussi de tâche
  \item Le CPU possède alors deux modes:
    \begin{itemize}
    \item  Utilisateur
    \item  Superviseur
    \end{itemize} 
  \item  Seul  le  mode  superviseur  (l'OS) permet  de  modifier  les
    association de la MMU
  \end{itemize}
  \note{Nous verrons  par la suite comment passer  du mode superviseur
    au mode utilisateur et vice versa}
\end{frame} 

\begin{frame}{La MMU - gestion des exceptions}
  Toutes les  addreses physiques ne  sont pas mappée sur  des addresse
  virtuelle
  \begin{itemize} 
  \item Une tâche A ne peut pas accèder à la mémoire d'une tâche B
  \item Protection contre les erreur de programmation
  \item Permet d'assurer la sécurité des système multi-utilisateur
  \item Une tâche à l'impression d'avoir toute la mémoire pour elle
  \end{itemize} 
\end{frame} 

\begin{frame}{La MMU - gestion des exceptions}
  Toutes les addresse  virtuelle ne sont pas mappées  sur des addresse
  physique
  \begin{itemize}
  \item  Lorsqu'une  tâche accède  à  une  addresse  non mappée.   Une
    exception est déclenché.  Cela permet  à l'OS de reprendre la main
    et de traiter l'erreur (souvent en tuant la tâche fautive)
  \item Lorsqu'une tâche souhaite allouer de la mémoire
    \begin{itemize}
    \item  La tâche demande à l'OS
    \item L'OS choisi un (ou plusieur) blocs de mémoire physique libre
    \item l'OS marque le bloc comme appartenant à la tâche
    \item L'OS choisi  un espace d'adresse virtuelle ou  mappé le bloc
      de mémoire
    \item L'OS met à jour la MMU
    \item L'OS retourne l'addresse virtuelle
    \end{itemize} 
  \end{itemize} 
\end{frame} 

\subsection{Optimisation possible grace à la MMU}

\begin{frame}{La MMU - gestion des exceptions}
  Le MMU permet à l'OS de mieux utiliser la mémoire:
  \begin{itemize} 
  \item  L'OS peut  donner  des esapce  d'addressage virtuel  contigue
    alors que la mémoire physique est fractionnée
  \item Le système n'alloue jamais la plage < 1024
    \begin{itemize}
    \item Cela donne une plage de valeur spéciale (ex: NULL)
    \item Ainsi,  lors du debug,  vous êtes certains qu'un  pointeur <
      1024 est non valide
    \item En  dehors des pointeur,  les nombre que l'on  manipule sont
      très  souvent <  1024.   Ce système  nous  permet de  rapidement
      repérer des cast abusif entre des integer et des pointeurs
    \end{itemize} 
  \item ``Sun a inventé le SegFault''
  \end{itemize} 
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Retarder l'association:
  \begin{itemize}
  \item Une tâche demande une allocation
  \item Le système  enregistre la demande dans le  Memory Manager mais
    ne modifie pas le MMU
  \item  Le  système  indique   à  la  tâche  que  l'allocation  s'est
    correctemenr déroulée
  \item Lorsque la tâche accède à cette page, une exception est levée
  \item Le système reprend la main
  \item Il remarque qu'il avait promis cette page
  \item Il alloue un bloc physique et met à jour la MMU
  \item Il rend la main à la tâche
  \item Tout est transparent pour elle
  \end{itemize}
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Utilisation de la Swap:
  \begin{itemize}
  \item Lorsque le système n'a plus assez de mémoire
  \item Il choisit une page physique qu'il copie sur le disque dur
  \item  Il  supprime  la  page   de  la  MMU  de  la  (les)  tache(s)
    concernée(s)
  \item Lorsque la tâche accèdera à la page, une exception sera levée
  \item Le système recupère alors la page sur le disque
  \item Le système reécrit la page dans la mémoire phyqsique
  \item  Il  fait  repointer  l'addresse  virtuelle  demandée  sur  la
    nouvelle page physique
  \item L'OS rend la main à la tâche
  \item Tout est transparent pour la tâche
  \end{itemize}
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Gestion des droits sur les pages
  \begin{itemize}
  \item    Il    est     possible    d'affecter    des    droits    en
    lecture/écriture/éxécution sur les pages gérée apr la MMU
  \item Une page contenant des  données constante (donné ou code) peut
    être mappée dans plusieurs tâche différente
  \item En retirant les droits en execution sur les page de donnée, on
    améliore la  sécurité du  système (impossible d'éxecuter  une page
    contenant des données)
  \item Une  page accessible  en écriture peut  être mappée  dans deux
    tâche afin de leur permettre de partager des données
    \end{itemize} 
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Simplification des accès au IO
  \begin{itemize} 
  \item La tâche demande de mapper un fichier en mémoire
  \item Le système  alloue un espace d'addressage égal  à la taille du
    fichier
  \item Le fichier en lui même n'est pas chargé en mémoire
  \item Lorsque la  tâche accès à un espace  du fichier, une exception
    est levée et la page demandée est chargée de manière tranparente
  \item Le  système marque la  page comme Read-Only. Lorsque  la tâche
    tente d'écrire dans la page,  une exception est levée, la page est
    marquée \emph{dirty}  , les  droit en écriture  sont donnée  et le
    système rend la main
  \item Lorsque  le système  à besoin de  mémoire, il peut  écrire les
    pages modifiée sur le disque et décharger la page de la mémoire
  \item Lorsqu'une  tâche demande un fichier deja  présent en mémoire,
    on map simplement la MMU sur  la page déjà présente (il faut alors
    gérer correctement le marquage \emph{dirty} de la page)
  \item  cf.   champ  \emph{buffer}  et \emph{cache}  de  la  commande
    \texttt{free}
  \end{itemize}
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Sécurisation des accès aux periphériques
  \begin{itemize}
  \item Lorsque  ls registres des périfériques sont  mappé en mémoire,
    on utilise la MMU pour y accèder
  \item Il  est possible d'autoriser  l'accès à un périphérique  à une
    tâche sans lui donner d'accès au reste du système
  \item Un système utilisant  très fortement cette méthode est appellé
    micro-kernel
  \item La méthode est peu utilisée sous Linux
  \item cf \emph{ioperm(2)}
  \end{itemize}
\end{frame}

\begin{frame}{Passage en mode superviseur}
  Un processus utilisateur ne peut pas passer en mode superviseur.

  Comment passer en mode superviseur?
  \begin{itemize} 
  \item Lorsqu'une interruption/exception est déclenchée
  \item Cela nous permet de gérer tous les cas précédants
  \end{itemize} 

  Comment appeller une fonction du système?
  \begin{itemize} 
  \item  Les  tâches ont  besoin  de  faire  des demandes  au  système
    (exemple: allouer de la mémoire)
  \item Ces fonctions système s'appellent des \emph{appels système} ou
    \emph{syscall} (section 2 des pages de man)
  \item  Elles ont  très  peu de  points  communs avec  les appels  de
    fonctions classiques
  \item   Chaque  \emph{syscall}   est   associé  à   un  numéro   (cf
    \texttt{sys/syscall.h}                   \texttt{asm/unistd\_32.h},
    \emph{syscalls(2)})
  \end{itemize}\end{itemize} 

\end{frame}

\begin{frame}{Passage en mode superviseur}
  Pour utiliser les \emph{appels systèmes} (cf \emph{syscall(2)}):
  \begin{itemize}
  \item On place les arguments sur la pile
  \item On place le numéro de l'interruption sur la pile
  \item On déclenche une interruption logicielle (\texttt{int 0x80})
  \item  Le  CPU  passe  en  mode  superviseur  et  appelle  l'ISR  de
    l'interruption
  \item L'OS prend  la main, regarde le premier element  de la pile et
    appelle la fonction correspondante (\texttt{asm-generic/unistd.h})
  \end{itemize}
  Il  existe maintenant  des instruction  spéciales sur  les  CPU pour
  optimiser les \emph{syscall}
\end{frame}

\begin{frame}{ Gestion de la mémoire}
  Thread versus Processus
  \begin{itemize}
  \item On  appelle les tâche  ayant des contexte  mémoires différents
    des \emph{Processus}
  \item  Il est  possible  d'éxécuter plusieurs  tâches  dans un  même
    contexte mémoire
  \item  Ces  tâche sont  appellée  \emph{threads} ou  \emph{processus
      lègers}
  \item Le fonctionnement  est alors identique au mode  sans MMU, avec
    les même défauts et avantage:
    \begin{itemize}
    \item  Pas  de protection  contre  les  erreurs programmation  des
      autres threads
    \item Partage de l'information simplifiée
    \item Passage d'une thread à une autre beaucoup plus rapide
    \end{itemize}
  \end{itemize}
  \note{Attention au latence lors de l'allocation, et du swap}
\end{frame} 

% \begin{frame}{Résumé sur le multiptâche. Commandes ps et pmap, et /proc}
% Memoire
%   \item pmem, \%mem, rss, rsz, rssize: Mémoire résidente, c'est à dire quantité de mémoire physqiue effectivement utilisé par le processus (par consequent, la memoire swapée n'est pas prise en compte). 
%   \item vsz,vsize : Taille de la plage d'addressage virtuelle du processus (sans les mapping de devices). Peut-être très supérieure à rss
%   \item  sz:     size in physical pages of the core image of the process. This includes text, data, and stack space. Device mappings are currently excluded; this is subject to change. See vsz and rss.

% Temps
%        %cpu, pcpu, cp      %CPU   cpu utilization of the process in "##.#" format. Currently, it is the CPU time used divided by the time the process has been running (cputime/realtime ratio), expressed as a percentage.
%                         It will not add up to 100% unless you are lucky. (alias pcpu).

%        bsdstart  START  time the command started. If the process was started less than 24 hours ago, the output format is " HH:MM", else it is "mmm dd" (where mmm is the three letters of the month). See also
%                         lstart, start, start_time, and stime.

%        bsdtime   TIME   accumulated cpu time, user + system. The display format is usually "MMM:SS", but can be shifted to the right if the process used more than 999 minutes of cpu time.

%        cputime, time   TIME   cumulative CPU time, "[dd-]hh:mm:ss" format. (alias time).

%        etime     ELAPSEDelapsed time since the process was started, in the form [[dd-]hh:]mm:ss.

%        lstart    STARTEDtime the command started. See also bsdstart, start, start_time, and stime.

%        c         C      processor utilization. Currently, this is the integer value of the percent usage over the lifetime of the process. (see %cpu).


%        args,cmd, command      COMMANDcommand with all its arguments as a string. Modifications to the arguments may be shown. The output in this column may contain spaces. A process marked <defunct> is partly dead, waiting
%                         to be fully destroyed by its parent. Sometimes the process args will be unavailable; when this happens, ps will instead print the executable name in brackets. (alias cmd, command). See
%                         also the comm format keyword, the -f option, and the c option.
%                         When specified last, this column will extend to the edge of the display. If ps can not determine display width, as when output is redirected (piped) into a file or another command, the
%                         output width is undefined. (it may be 80, unlimited, determined by the TERM variable, and so on) The COLUMNS environment variable or --cols option may be used to exactly determine the
%                         width in this case. The w or -w option may be also be used to adjust width.


%        class, cls, policy, sched     scheduling class of the process. (alias policy, cls). Field's possible values are:
%                         -   not reported
%                         TS  SCHED_OTHER
%                         FF  SCHED_FIFO
%                         RR  SCHED_RR
%                         B   SCHED_BATCH
%                         ISO SCHED_ISO
%                         IDL SCHED_IDLE
%                         ?   unknown value

%        fname     COMMANDfirst 8 bytes of the base name of the process's executable file. The output in this column may contain spaces.

%        comm      COMMANDcommand name (only the executable name). Modifications to the command name will not be shown. A process marked <defunct> is partly dead, waiting to be fully destroyed by its parent. The
%                         output in this column may contain spaces. (alias ucmd, ucomm). See also the args format keyword, the -f option, and the c option.
%                         When specified last, this column will extend to the edge of the display. If ps can not determine display width, as when output is redirected (piped) into a file or another command, the
%                         output width is undefined. (it may be 80, unlimited, determined by the TERM variable, and so on) The COLUMNS environment variable or --cols option may be used to exactly determine the
%                         width in this case. The w or -w option may be also be used to adjust width.


% Droits
%        {e,f,r,s}uid  uid effectif/filesystem/réel/sauvegardé
%        {e,f,r,s}user  utilisateur effectif/filesystem/réel/sauvegardé
%        {e,f,r,s}gid  gid effectif/filesystem/réel/sauvegardé
%        {e,f,r,s}groupe  groupe effectif/filesystem/réel/sauvegardé

%        pgid, pgrp   process group ID or, equivalently, the process ID of the process group leader. (alias pgrp).


%        eip       EIP    instruction pointer.

%        esp       ESP    stack pointer.



%        f         F      flags associated with the process, see the PROCESS FLAGS section. (alias flag, flags).

%        flag      F      see f. (alias f, flags).

%        flags     F      see f. (alias f, flag).


% Signaux:
%        blocked   BLOCKEDmask of the blocked signals, see signal(7). According to the width of the field, a 32-bit or 64-bit mask in hexadecimal format is displayed. (alias sig_block, sigmask).

%        caught    CAUGHT mask of the caught signals, see signal(7). According to the width of the field, a 32 or 64 bits mask in hexadecimal format is displayed. (alias sig_catch, sigcatch).

%        ignored   IGNOREDmask of the ignored signals, see signal(7). According to the width of the field, a 32-bit or 64-bit mask in hexadecimal format is displayed. (alias sig_ignore, sigignore).

%        label     LABEL  security label, most commonly used for SE Linux context data. This is for the Mandatory Access Control ("MAC") found on high-security systems.


%        lwp       LWP    lwp (light weight process, or thread) ID of the lwp being reported. (alias spid, tid).

%        ni, nice        NI     nice value. This ranges from 19 (nicest) to -20 (not nice to others), see nice(1). (alias nice).

%        nlwp      NLWP   number of lwps (threads) in the process. (alias thcount).

%        nwchan    WCHAN  address of the kernel function where the process is sleeping (use wchan if you want the kernel function name). Running tasks will display a dash ('-') in this column.


%        pending   PENDINGmask of the pending signals. See signal(7). Signals pending on the process are distinct from signals pending on individual threads. Use the m option or the -m option to see both.
%                         According to the width of the field, a 32-bit or 64-bit mask in hexadecimal format is displayed. (alias sig).

%        pid       PID    process ID number of the process.


%        ppid      PPID   parent process ID.

%        pri       PRI    priority of the process. Higher number means lower priority

%        psr       PSR    processor that process is currently assigned to.



%        rssize    RSS    see rss. (alias rss, rsz).

%        rsz       RSZ    see rss. (alias rss, rssize).

%        rtprio    RTPRIO realtime priority.


%        s         S      minimal state display (one character). See section PROCESS STATE CODES for the different values. See also stat if you want additional information displayed. (alias state).


%        sess      SESS   session ID or, equivalently, the process ID of the session leader. (alias session, sid).

%        sgi_p     P      processor that the process is currently executing on. Displays "*" if the process is not currently running or runnable.

%        sid       SID    see sess. (alias sess, session).

%        sig       PENDINGsee pending. (alias pending, sig_pend).


%        sigcatch  CAUGHT see caught. (alias caught, sig_catch).

%        sigignore IGNOREDsee ignored. (alias ignored, sig_ignore).

%        sigmask   BLOCKEDsee blocked. (alias blocked, sig_block).

%        size      SZ     approximate amount of swap space that would be required if the process were to dirty all writable pages and then be swapped out. This number is very rough!

%        spid      SPID   see lwp. (alias lwp, tid).

%        stackp    STACKP address of the bottom (start) of stack for the process.

%        start     STARTEDtime the command started. If the process was started less than 24 hours ago, the output format is "HH:MM:SS", else it is "  mmm dd" (where mmm is a three-letter month name). See also
%                         lstart, bsdstart, start_time, and stime.

%        start_timeSTART  starting time or date of the process. Only the year will be displayed if the process was not started the same year ps was invoked, or "mmmdd" if it was not started the same day,
%                         or "HH:MM" otherwise. See also bsdstart, start, lstart, and stime.

%        stat      STAT   multi-character process state. See section PROCESS STATE CODES for the different values meaning. See also s and state if you just want the first character displayed.

%        state     S      see s. (alias s).


%        thcount   THCNT  see nlwp. (alias nlwp). number of kernel threads owned by the process.

%        tid       TID    see lwp. (alias lwp).


%        tname     TTY    controlling tty (terminal). (alias tt, tty).

%        tpgid     TPGID  ID of the foreground process group on the tty (terminal) that the process is connected to, or -1 if the process is not connected to a tty.

%        tt, tty        TT     controlling tty (terminal). (alias tname, tty).

%        ucmd      CMD    see comm. (alias comm, ucomm).

%        ucomm     COMMANDsee comm. (alias comm, ucmd).

%        wchan     WCHAN  name of the kernel function in which the process is sleeping, a "-" if the process is running, or a "*" if the process is multi-threaded and ps is not displaying threads.
% \note{On doit être capable de décrire toute les entrée de la commande ps}

% \end{frame} 

\begin{frame}{multitâche, MMU et Temps réel} 
  \begin{itemize}
  \item Le multitâche permet une meilleure gestion de la concurence
  \item MMU à de multiple avantages (sécurité, optimisation)
  \item En revanche le fonctionnement  de la MMU entraine de multiples
    exceptions.
  \item Une allocation mémoire peut d'un seul changer tout le mapping
  \item Un accès en mémoire  peut être immédiat 100 fois mais demander
    un accès aux disque la 101eme fois
  \item  Il devient  difficile de  garantir le  temps de  calcul d'une
    fonction
  \item Les fonctions systèmes mlock et \texttt{mlock\_all} permettent
    de  demander  à Linux  de  garder des  page  (ou  la totatlité  en
    mémoire)
  \item  Il ne  faut pas  oublié d'allouer  uen pile  suffisante avant
    d'appeller \texttt{mlock\_all}
  \item Néanmoins, cela ne change pas que l'allocation dynamique ne se
    fait pas en temps constant
  \end{itemize} 
\end{frame} 



